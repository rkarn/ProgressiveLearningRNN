{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "from ray.tune import track\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "try:\n",
    "    tf.get_logger().setLevel('INFO')\n",
    "except Exception as exc:\n",
    "    print(exc)\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "import ray\n",
    "from ray import tune\n",
    "import time\n",
    "import inspect\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "'''\n",
    "class TuneReporterCallback(keras.callbacks.Callback):\n",
    "    \"\"\"Tune Callback for Keras.\n",
    "    \n",
    "    The callback is invoked every epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, logs={}):\n",
    "        self.iteration = 0\n",
    "        super(TuneReporterCallback, self).__init__()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.iteration += 1\n",
    "        track.log(keras_info=logs, mean_accuracy=logs.get(\"accuracy\"), mean_loss=logs.get(\"loss\"))\n",
    "    \n",
    "'''   \n",
    "class TuneReporterCallback(keras.callbacks.Callback):\n",
    "    \"\"\"Tune Callback for Keras.\n",
    "    \n",
    "    The callback is invoked every epoch.\n",
    "    \"\"\"\n",
    "    def __init__(self, logs={}):\n",
    "        self.iteration = 0\n",
    "        super(TuneReporterCallback, self).__init__()\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.iteration += 1\n",
    "        if \"acc\" in logs:\n",
    "            tune.report(keras_info=logs, val_loss=logs['val_loss'], mean_accuracy=logs[\"acc\"], f1_m = logs['f1_m'], precision_m=logs['precision_m'], recall_m=logs['recall_m'])\n",
    "        else:\n",
    "            tune.report(keras_info=logs, val_loss=logs['val_loss'], mean_accuracy=logs.get(\"accuracy\"), f1_m = logs.get('f1_m'), precision_m=logs.get('precision_m'), recall_m=logs.get('recall_m'))\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "from keras import backend as K\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))        \n",
    "        \n",
    "def create_model(learning_rate, RNN_units, dropout):\n",
    "    assert learning_rate > 0 and RNN_units > 0 and dropout > 0, \"Did you set the right configuration?\"\n",
    "    input_shape = (28, 28)\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(units=int(RNN_units), dropout=dropout, input_shape=input_shape,  activation='relu', name='RNN'))\n",
    "    model.add(Dense(num_labels, activation = 'softmax', name = 'dense_output'))\n",
    "    #optimizer = SGD(lr=learning_rate)\n",
    "    optimizer = Adam(clipvalue=0.5, lr=learning_rate)\n",
    "    model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy',f1_m,precision_m, recall_m])\n",
    "    return model\n",
    "        \n",
    "def tune_mnist(config):  \n",
    "    model = create_model(learning_rate=config['lr'], RNN_units=int(config['unit']), dropout=config['dropout'])  # TODO: Change me.\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        \"model.h5\", monitor='loss', save_best_only=True, save_freq=2)\n",
    "\n",
    "    # Enable Tune to make intermediate decisions by using a Tune Callback hook. This is Keras specific.\n",
    "    callbacks = [checkpoint_callback, TuneReporterCallback()]\n",
    "    task_dataset = pickle.load(open('/root/Raytune_MNIST_RNN/task_dataset.pkl', \"rb\"))\n",
    "    image_size = 28\n",
    "    X_train = np.reshape(task_dataset[0],[-1, image_size, image_size]) \n",
    "    Y_train = task_dataset[1]\n",
    "    X_test = np.reshape(task_dataset[2],[-1, image_size, image_size]) \n",
    "    Y_test = task_dataset[3]\n",
    "    # Train the model\n",
    "    hist = model.fit(\n",
    "        X_train, Y_train, \n",
    "        validation_data=(X_test, Y_test),\n",
    "        verbose=0, \n",
    "        batch_size=100, \n",
    "        epochs=10, \n",
    "        callbacks=callbacks)\n",
    "    for key in hist.history:\n",
    "        print(key)\n",
    "\n",
    "# Random and uniform sampling for hypertune\n",
    "def random_search(task_data, task_id=0, cpu_resouce_fed=4):\n",
    "    import numpy as np; np.random.seed(5)  \n",
    "    hyperparameter_space = {\n",
    "        \"lr\": tune.loguniform(0.001, 0.1),  \n",
    "        \"unit\": tune.uniform(20, 50),\n",
    "        \"dropout\": tune.loguniform(0.01, 0.3),\n",
    "    }  \n",
    "    num_samples = 10 \n",
    "    ####################################################################################################\n",
    "    ################ This is just a validation function for tutorial purposes only. ####################\n",
    "    HP_KEYS = [\"lr\", \"unit\", \"dropout\"]\n",
    "    assert all(key in hyperparameter_space for key in HP_KEYS), (\n",
    "        \"The hyperparameter space is not fully designated. It must include all of {}\".format(HP_KEYS))\n",
    "    ######################################################################################################\n",
    "\n",
    "    ray.shutdown()  # Restart Ray defensively in case the ray connection is lost. \n",
    "    ray.init(log_to_driver=False, num_cpus=cpu_resouce_fed)\n",
    "    # We clean out the logs before running for a clean visualization later.\n",
    "    ! rm -rf ~/ray_results/tune_mnist$task_id\n",
    "    analysis = tune.run(\n",
    "        tune_mnist, \n",
    "        name=\"Random_mnist_task\"+str(task_id),\n",
    "        verbose=1, \n",
    "        config=hyperparameter_space,\n",
    "        num_samples=num_samples)\n",
    "    time.sleep(1)\n",
    "\n",
    "    assert len(analysis.trials) > 2, \"Did you set the correct number of samples?\"\n",
    "\n",
    "    # Obtain the directory where the best model is saved.\n",
    "    print(\"You can use any of the following columns to get the best model: \\n{}.\".format(\n",
    "        [k for k in analysis.dataframe() if k.startswith(\"keras_info\")]))\n",
    "    print(\"=\" * 10)\n",
    "    logdir = analysis.get_best_logdir(\"keras_info/val_acc\", mode=\"max\")\n",
    "    print('Best model:',analysis.get_best_trial(metric='keras_info/val_acc', mode='max'), \n",
    "          'lr:', analysis.get_best_config(metric='keras_info/val_acc', mode='max')['lr'], 'unit:', analysis.get_best_config(metric='keras_info/val_acc', mode='max')['unit'], 'dropout:', analysis.get_best_config(metric='keras_info/val_acc', mode='max')['dropout'] )\n",
    "    # We saved the model as `model.h5` in the logdir of the trial.\n",
    "    from tensorflow.keras.models import load_model\n",
    "    tuned_model = load_model(logdir + \"/model.h5\", custom_objects =  {'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m})\n",
    "    tuned_model.summary()\n",
    "    image_size = 28\n",
    "    X_test = np.reshape(task_data[2],[-1, image_size, image_size])  \n",
    "    Y_test = task_data[3]\n",
    "    tuned_loss, tuned_accuracy, f1_score, precision, recall = tuned_model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print(\"Loss is {:0.4f}\".format(tuned_loss))\n",
    "    print(\"Tuned accuracy is {:0.4f}\".format(tuned_accuracy))\n",
    "    print ('F1-score = {0}'.format(f1_score))\n",
    "    print ('Precision = {0}'.format(precision))\n",
    "    print ('Recall = {0}'.format(recall))\n",
    "    return(analysis.get_best_config(metric='keras_info/acc', mode='max'))\n",
    "\n",
    "#PBT population based sampling \n",
    "def mutation_pbtsearch(task_data, task_id=0, cpu_resouce_fed=4):\n",
    "    from ray.tune.schedulers import PopulationBasedTraining\n",
    "    from ray.tune.utils import validate_save_restore\n",
    "    scheduler = PopulationBasedTraining(\n",
    "        time_attr=\"training_iteration\",\n",
    "        metric=\"mean_accuracy\",\n",
    "        mode=\"max\",\n",
    "        perturbation_interval=20,\n",
    "        hyperparam_mutations={\n",
    "            # distribution for resampling\n",
    "            \"lr\": lambda: np.random.uniform(0.0001, 1),\n",
    "            # allow perturbations within this set of categorical values\n",
    "            \"unit\": [40, 60, 100], \"dropout\": [0.1, 0.2, 0.3], \n",
    "        }\n",
    "    )\n",
    "\n",
    "    old_dirs = os.listdir('/root/ray_results/')\n",
    "\n",
    "    ray.shutdown()  # Restart Ray defensively in case the ray connection is lost. \n",
    "    ray.init(log_to_driver=False, num_cpus=cpu_resouce_fed)\n",
    "    ! rm -rf ~/ray_results/PBT_mnist_task$task_id\n",
    "    analysis = tune.run(\n",
    "        tune_mnist,\n",
    "        name=\"PBT_mnist_task\"+str(task_id),\n",
    "        scheduler=scheduler,\n",
    "        reuse_actors=True,\n",
    "        verbose=1,\n",
    "        stop={\n",
    "            \"training_iteration\": 100,\n",
    "        },\n",
    "        num_samples=10,\n",
    "\n",
    "        # PBT starts by training many neural networks in parallel with random hyperparameters. \n",
    "        config={\n",
    "        \"lr\": tune.loguniform(0.001, 0.1),  \n",
    "        \"unit\": tune.uniform(20, 50),\n",
    "        \"dropout\": tune.loguniform(0.01, 0.3),\n",
    "    } )\n",
    "    time.sleep(1)\n",
    "    print(\"You can use any of the following columns to get the best model: \\n{}.\".format(\n",
    "        [k for k in analysis.dataframe() if k.startswith(\"keras_info\")]))\n",
    "    print(\"=\" * 10)\n",
    "    logdir = analysis.get_best_logdir(\"keras_info/val_acc\", mode=\"max\")\n",
    "    print('Best model:',analysis.get_best_trial(metric='keras_info/val_acc', mode='max'), \n",
    "          analysis.get_best_config(metric='keras_info/val_acc', mode='max'))\n",
    "    # We saved the model as `model.h5` in the logdir of the trial.\n",
    "    from tensorflow.keras.models import load_model\n",
    "    tuned_model = load_model(logdir + \"/model.h5\", custom_objects =  {'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m})\n",
    "    tuned_model.summary()\n",
    "    image_size = 28\n",
    "    X_test = np.reshape(task_data[2],[-1, image_size, image_size])\n",
    "    Y_test = task_data[3]\n",
    "    tuned_loss, tuned_accuracy, f1_score, precision, recall = tuned_model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print(\"Loss is {:0.4f}\".format(tuned_loss))\n",
    "    print(\"Tuned accuracy is {:0.4f}\".format(tuned_accuracy))\n",
    "    print ('F1-score = {0}'.format(f1_score))\n",
    "    print ('Precision = {0}'.format(precision))\n",
    "    print ('Recall = {0}'.format(recall))\n",
    "    return(analysis.get_best_config(metric='keras_info/acc', mode='max'))\n",
    "\n",
    "#ASHA Schedular\n",
    "def ASHA_search(task_data, task_id=0, cpu_resouce_fed=4):\n",
    "    from ray.tune.schedulers import ASHAScheduler\n",
    "    ray.shutdown()  # Restart Ray defensively in case the ray connection is lost. \n",
    "    ray.init(log_to_driver=False, num_cpus=cpu_resouce_fed)\n",
    "    custom_scheduler = ASHAScheduler(\n",
    "        metric='mean_accuracy',\n",
    "        mode=\"max\",\n",
    "        reduction_factor = 4,\n",
    "        grace_period=1)# TODO: Add a ASHA as custom scheduler here\n",
    "    hyperparameter_space={\n",
    "        \"lr\": tune.loguniform(0.001, 0.1),  \n",
    "        \"unit\": tune.uniform(20, 50),\n",
    "        \"dropout\": tune.loguniform(0.01, 0.3),\n",
    "    } \n",
    "    ray.shutdown()  # Restart Ray defensively in case the ray connection is lost. \n",
    "    ray.init(log_to_driver=False, num_cpus=cpu_resouce_fed)\n",
    "    ! rm -rf ~/ray_results/ASHA_mnist_task$task_id\n",
    "    analysis = tune.run(\n",
    "        tune_mnist, \n",
    "        scheduler=custom_scheduler, \n",
    "        config=hyperparameter_space, \n",
    "        verbose=1,\n",
    "        num_samples=10,\n",
    "        #resources_per_trial={\"cpu\":4},\n",
    "        name=\"ASHA_mnist_task\"+str(task_id)  # This is used to specify the logging directory.\n",
    "    )\n",
    "    time.sleep(1)\n",
    "    print(\"You can use any of the following columns to get the best model: \\n{}.\".format(\n",
    "        [k for k in analysis.dataframe() if k.startswith(\"keras_info\")]))\n",
    "    print(\"=\" * 10)\n",
    "    logdir = analysis.get_best_logdir(\"keras_info/acc\", mode=\"max\")\n",
    "    print('Best model:',analysis.get_best_trial(metric='keras_info/acc', mode='max'), \n",
    "          analysis.get_best_config(metric='keras_info/acc', mode='max'))\n",
    "    # We saved the model as `model.h5` in the logdir of the trial.\n",
    "    from tensorflow.keras.models import load_model\n",
    "    tuned_model = load_model(logdir + \"/model.h5\", custom_objects =  {'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m})\n",
    "    tuned_model.summary()\n",
    "    image_size = 28\n",
    "    X_test = np.reshape(task_data[2],[-1, image_size, image_size])\n",
    "    Y_test = task_data[3]\n",
    "    tuned_loss, tuned_accuracy, f1_score, precision, recall = tuned_model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print(\"Loss is {:0.4f}\".format(tuned_loss))\n",
    "    print(\"Tuned accuracy is {:0.4f}\".format(tuned_accuracy))\n",
    "    print ('F1-score = {0}'.format(f1_score))\n",
    "    print ('Precision = {0}'.format(precision))\n",
    "    print ('Recall = {0}'.format(recall))\n",
    "    return(analysis.get_best_config(metric='keras_info/acc', mode='max'))\n",
    "\n",
    "\n",
    "#HyperOpt Search \n",
    "def hyperopt_search(task_data, task_id=0, cpu_resouce_fed=4):\n",
    "    from ray.tune.suggest import ConcurrencyLimiter\n",
    "    from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "    from ray.tune.suggest.hyperopt import HyperOptSearch\n",
    "\n",
    "    \n",
    "    search_space={\n",
    "        \"lr\": tune.loguniform(0.001, 0.1),  \n",
    "        \"unit\": tune.uniform(20, 50),\n",
    "        \"dropout\": tune.loguniform(0.01, 0.3),\n",
    "    }\n",
    "    current_best_params = [{\n",
    "    'lr': 0.01,\n",
    "    'unit': 25,\n",
    "    'dropout': 0.2,\n",
    "    }]\n",
    "    scheduler = AsyncHyperBandScheduler()\n",
    "    \n",
    "    algo = HyperOptSearch(points_to_evaluate=current_best_params)\n",
    "    algo = ConcurrencyLimiter(algo, max_concurrent=cpu_resouce_fed)\n",
    "    ray.shutdown()  # Restart Ray defensively in case the ray connection is lost. \n",
    "    ray.init(log_to_driver=False, num_cpus=cpu_resouce_fed)\n",
    "    ! rm -rf ~/ray_results/BayesOptSearch_mnist_task$task_id\n",
    "    analysis =tune.run(tune_Drebin,\n",
    "        name=\"hyperopt_mnist_task\"+str(task_id), verbose = 1,\n",
    "        scheduler=scheduler,\n",
    "        search_alg=algo,\n",
    "        num_samples=10, \n",
    "        metric=\"mean_accuracy\",\n",
    "        mode=\"max\",\n",
    "        config=search_space,\n",
    "        stop={\"training_iteration\": 150})\n",
    "    time.sleep(1)\n",
    "    #from ray.tune import Analysis as analysis\n",
    "    #analysis = ray.tune.Analysis('/root/ray_results/BayesOptSearch_ASNM') \n",
    "    print(\"You can use any of the following columns to get the best model: \\n{}.\".format(\n",
    "        [k for k in analysis.dataframe() if k.startswith(\"keras_info\")]))\n",
    "    print(\"=\" * 10)\n",
    "    logdir = analysis.get_best_logdir(\"keras_info/acc\", mode=\"max\")\n",
    "    print('Best model:', analysis.get_best_config(metric='keras_info/acc', mode='max'))\n",
    "    # We saved the model as `model.h5` in the logdir of the trial.\n",
    "    from tensorflow.keras.models import load_model\n",
    "    tuned_model = load_model(logdir + \"/model.h5\", custom_objects =  {'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m})\n",
    "    tuned_model.summary()\n",
    "    image_size = 28\n",
    "    X_test = np.reshape(task_data[2],[-1, image_size, image_size])\n",
    "    Y_test = task_data[3]\n",
    "    tuned_loss, tuned_accuracy, f1_score, precision, recall = tuned_model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print(\"Loss is {:0.4f}\".format(tuned_loss))\n",
    "    print(\"Tuned accuracy is {:0.4f}\".format(tuned_accuracy))\n",
    "    print ('F1-score = {0}'.format(f1_score))\n",
    "    print ('Precision = {0}'.format(precision))\n",
    "    print ('Recall = {0}'.format(recall))\n",
    "    return(analysis.get_best_config(metric='keras_info/acc', mode='max'))\n",
    "\n",
    "def BayesOptSearch(task_data, task_id=0, cpu_resouce_fed=4):\n",
    "    from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "    from ray.tune.suggest import ConcurrencyLimiter\n",
    "    from ray.tune.suggest.bayesopt import BayesOptSearch\n",
    "    \n",
    "    search_space={\n",
    "        \"lr\": tune.loguniform(0.001, 0.1),  \n",
    "        \"unit\": tune.uniform(20, 50),\n",
    "        \"dropout\": tune.loguniform(0.01, 0.3),\n",
    "    } \n",
    "    scheduler = AsyncHyperBandScheduler()\n",
    "    \n",
    "    algo = ConcurrencyLimiter(BayesOptSearch(utility_kwargs={\n",
    "        \"kind\": \"ucb\",\n",
    "        \"kappa\": 2.5,\n",
    "        \"xi\": 0.0\n",
    "        }, metric = 'mean_accuracy', mode = 'max'), \n",
    "        max_concurrent=cpu_resouce_fed)\n",
    "    ray.shutdown()  # Restart Ray defensively in case the ray connection is lost. \n",
    "    ray.init(log_to_driver=False, num_cpus=cpu_resouce_fed)\n",
    "    ! rm -rf ~/ray_results/BayesOptSearch_mnist_task$task_id\n",
    "    analysis =tune.run(tune_mnist,\n",
    "        name=\"BayesOptSearch_mnist_task\"+str(task_id), verbose = 1,\n",
    "        scheduler=scheduler,\n",
    "        search_alg=algo,\n",
    "        num_samples=100, \n",
    "        metric=\"mean_accuracy\",\n",
    "        mode=\"max\",\n",
    "        config=search_space,\n",
    "        stop={\"training_iteration\": 150})\n",
    "    time.sleep(1)\n",
    "    #from ray.tune import Analysis as analysis\n",
    "    #analysis = ray.tune.Analysis('/root/ray_results/BayesOptSearch_ASNM') \n",
    "    print(\"You can use any of the following columns to get the best model: \\n{}.\".format(\n",
    "        [k for k in analysis.dataframe() if k.startswith(\"keras_info\")]))\n",
    "    print(\"=\" * 10)\n",
    "    logdir = analysis.get_best_logdir(\"keras_info/acc\", mode=\"max\")\n",
    "    print('Best model:', analysis.get_best_config(metric='keras_info/acc', mode='max'))\n",
    "    # We saved the model as `model.h5` in the logdir of the trial.\n",
    "    from tensorflow.keras.models import load_model\n",
    "    tuned_model = load_model(logdir + \"/model.h5\", custom_objects =  {'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m})\n",
    "    tuned_model.summary()\n",
    "    image_size = 28\n",
    "    X_test = np.reshape(task_data[2],[-1, image_size, image_size])\n",
    "    Y_test = task_data[3]\n",
    "    tuned_loss, tuned_accuracy, f1_score, precision, recall = tuned_model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print(\"Loss is {:0.4f}\".format(tuned_loss))\n",
    "    print(\"Tuned accuracy is {:0.4f}\".format(tuned_accuracy))\n",
    "    print ('F1-score = {0}'.format(f1_score))\n",
    "    print ('Precision = {0}'.format(precision))\n",
    "    print ('Recall = {0}'.format(recall))\n",
    "    return(analysis.get_best_config(metric='keras_info/acc', mode='max'))\n",
    "\n",
    "\n",
    "def NeverGradSearch(task_data, task_id=0, cpu_resouce_fed=4):\n",
    "    from ray.tune.suggest import ConcurrencyLimiter\n",
    "    from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "    from ray.tune.suggest.nevergrad import NevergradSearch\n",
    "    import nevergrad as ng\n",
    "    \n",
    "    search_space={\n",
    "        \"lr\": tune.loguniform(0.001, 0.1),  \n",
    "        \"unit\": tune.uniform(20, 50),\n",
    "        \"dropout\": tune.loguniform(0.01, 0.3),\n",
    "    } \n",
    "    scheduler = AsyncHyperBandScheduler()\n",
    "    \n",
    "    algo = NevergradSearch(\n",
    "        optimizer=ng.optimizers.OnePlusOne,\n",
    "        # space=space,  # If you want to set the space manually\n",
    "    )\n",
    "    algo = ConcurrencyLimiter(algo, max_concurrent=cpu_resouce_fed)\n",
    "    ray.shutdown()  # Restart Ray defensively in case the ray connection is lost. \n",
    "    ray.init(log_to_driver=False, num_cpus=cpu_resouce_fed)\n",
    "    ! rm -rf ~/ray_results/BayesOptSearch_mnist_task$task_id\n",
    "    analysis =tune.run(tune_mnist,\n",
    "        name=\"NeverGradSearch_mnist_task\"+str(task_id), verbose = 1,\n",
    "        scheduler=scheduler,\n",
    "        search_alg=algo,\n",
    "        num_samples=10, \n",
    "        metric=\"mean_accuracy\",\n",
    "        mode=\"max\",\n",
    "        config=search_space,\n",
    "        stop={\"training_iteration\": 150})\n",
    "    time.sleep(1)\n",
    "    #from ray.tune import Analysis as analysis\n",
    "    #analysis = ray.tune.Analysis('/root/ray_results/BayesOptSearch_ASNM') \n",
    "    print(\"You can use any of the following columns to get the best model: \\n{}.\".format(\n",
    "        [k for k in analysis.dataframe() if k.startswith(\"keras_info\")]))\n",
    "    print(\"=\" * 10)\n",
    "    logdir = analysis.get_best_logdir(\"keras_info/acc\", mode=\"max\")\n",
    "    print('Best model:', analysis.get_best_config(metric='keras_info/acc', mode='max'))\n",
    "    # We saved the model as `model.h5` in the logdir of the trial.\n",
    "    from tensorflow.keras.models import load_model\n",
    "    tuned_model = load_model(logdir + \"/model.h5\", custom_objects =  {'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m})\n",
    "    tuned_model.summary()\n",
    "    image_size = 28\n",
    "    X_test = np.reshape(task_data[2],[-1, image_size, image_size])\n",
    "    Y_test = task_data[3]\n",
    "    tuned_loss, tuned_accuracy, f1_score, precision, recall = tuned_model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print(\"Loss is {:0.4f}\".format(tuned_loss))\n",
    "    print(\"Tuned accuracy is {:0.4f}\".format(tuned_accuracy))\n",
    "    print ('F1-score = {0}'.format(f1_score))\n",
    "    print ('Precision = {0}'.format(precision))\n",
    "    print ('Recall = {0}'.format(recall))\n",
    "    return(analysis.get_best_config(metric='keras_info/acc', mode='max'))\n",
    "\n",
    "def OptunaSearch(task_data, task_id=0, cpu_resouce_fed=4):\n",
    "    from ray.tune.suggest import ConcurrencyLimiter\n",
    "    from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "    from ray.tune.suggest.optuna import OptunaSearch\n",
    "    \n",
    "    search_space={\n",
    "        \"lr\": tune.loguniform(0.001, 0.1),  \n",
    "        \"unit\": tune.uniform(20, 50),\n",
    "        \"dropout\": tune.loguniform(0.01, 0.3),\n",
    "    } \n",
    "    scheduler = AsyncHyperBandScheduler()\n",
    "    \n",
    "    algo = OptunaSearch(metric=\"mean_accuracy\",\n",
    "        mode=\"max\")\n",
    "    algo = ConcurrencyLimiter(algo, max_concurrent=cpu_resouce_fed)\n",
    "    ray.shutdown()  # Restart Ray defensively in case the ray connection is lost. \n",
    "    ray.init(log_to_driver=False, num_cpus=cpu_resouce_fed)\n",
    "    ! rm -rf ~/ray_results/BayesOptSearch_mnist_task$task_id\n",
    "    analysis =tune.run(tune_mnist,\n",
    "        name=\"OptunaSearch_mnist_task\"+str(task_id), verbose = 1,\n",
    "        scheduler=scheduler,\n",
    "        search_alg=algo,\n",
    "        num_samples=10, \n",
    "        metric=\"mean_accuracy\",\n",
    "        mode=\"max\",\n",
    "        config=search_space,\n",
    "        stop={\"training_iteration\": 150})\n",
    "    time.sleep(1)\n",
    "    #from ray.tune import Analysis as analysis\n",
    "    #analysis = ray.tune.Analysis('/root/ray_results/BayesOptSearch_ASNM') \n",
    "    print(\"You can use any of the following columns to get the best model: \\n{}.\".format(\n",
    "        [k for k in analysis.dataframe() if k.startswith(\"keras_info\")]))\n",
    "    print(\"=\" * 10)\n",
    "    logdir = analysis.get_best_logdir(\"keras_info/acc\", mode=\"max\")\n",
    "    print('Best model:', analysis.get_best_config(metric='keras_info/acc', mode='max'))\n",
    "    # We saved the model as `model.h5` in the logdir of the trial.\n",
    "    from tensorflow.keras.models import load_model\n",
    "    tuned_model = load_model(logdir + \"/model.h5\", custom_objects =  {'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m})\n",
    "    tuned_model.summary()\n",
    "    image_size = 28\n",
    "    X_test = np.reshape(task_data[2],[-1, image_size, image_size])\n",
    "    Y_test = task_data[3]\n",
    "    tuned_loss, tuned_accuracy, f1_score, precision, recall = tuned_model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print(\"Loss is {:0.4f}\".format(tuned_loss))\n",
    "    print(\"Tuned accuracy is {:0.4f}\".format(tuned_accuracy))\n",
    "    print ('F1-score = {0}'.format(f1_score))\n",
    "    print ('Precision = {0}'.format(precision))\n",
    "    print ('Recall = {0}'.format(recall))\n",
    "    return(analysis.get_best_config(metric='keras_info/acc', mode='max'))\n",
    "\n",
    "def ZOOptSearch(task_data, task_id=0, cpu_resouce_fed=4):\n",
    "    from ray.tune.suggest.zoopt import ZOOptSearch\n",
    "    from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "    from zoopt import ValueType  # noqa: F401\n",
    "    \n",
    "    search_space={\n",
    "        \"lr\": tune.loguniform(0.001, 0.1),  \n",
    "        \"unit\": tune.uniform(20, 50),\n",
    "        \"dropout\": tune.loguniform(0.01, 0.3),\n",
    "    }\n",
    "    scheduler = AsyncHyperBandScheduler()\n",
    "    num_samples = 10\n",
    "    zoopt_search_config = {\n",
    "        \"parallel_num\": cpu_resouce_fed,\n",
    "    }\n",
    "\n",
    "    algo = ZOOptSearch(\n",
    "        algo=\"Asracos\",  # only support ASRacos currently\n",
    "        budget=num_samples,\n",
    "        # dim_dict=space,  # If you want to set the space yourself\n",
    "        **zoopt_search_config)\n",
    "    ray.shutdown()  # Restart Ray defensively in case the ray connection is lost. \n",
    "    ray.init(log_to_driver=False, num_cpus=cpu_resouce_fed)\n",
    "    ! rm -rf ~/ray_results/BayesOptSearch_mnist_task$task_id\n",
    "    analysis =tune.run(tune_mnist,\n",
    "        name=\"ZOOptSearch_mnist_task\"+str(task_id), verbose = 1,\n",
    "        scheduler=scheduler,\n",
    "        search_alg=algo,\n",
    "        num_samples=num_samples, \n",
    "        metric=\"mean_accuracy\",\n",
    "        mode=\"max\",\n",
    "        config=search_space,\n",
    "        stop={\"training_iteration\": 150})\n",
    "    time.sleep(1)\n",
    "    #from ray.tune import Analysis as analysis\n",
    "    #analysis = ray.tune.Analysis('/root/ray_results/BayesOptSearch_ASNM') \n",
    "    print(\"You can use any of the following columns to get the best model: \\n{}.\".format(\n",
    "        [k for k in analysis.dataframe() if k.startswith(\"keras_info\")]))\n",
    "    print(\"=\" * 10)\n",
    "    logdir = analysis.get_best_logdir(\"keras_info/acc\", mode=\"max\")\n",
    "    print('Best model:', analysis.get_best_config(metric='keras_info/acc', mode='max'))\n",
    "    # We saved the model as `model.h5` in the logdir of the trial.\n",
    "    from tensorflow.keras.models import load_model\n",
    "    tuned_model = load_model(logdir + \"/model.h5\", custom_objects =  {'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m})\n",
    "    tuned_model.summary()\n",
    "    image_size = 28\n",
    "    X_test = np.reshape(task_data[2],[-1, image_size, image_size])\n",
    "    Y_test = task_data[3]\n",
    "    tuned_loss, tuned_accuracy, f1_score, precision, recall = tuned_model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print(\"Loss is {:0.4f}\".format(tuned_loss))\n",
    "    print(\"Tuned accuracy is {:0.4f}\".format(tuned_accuracy))\n",
    "    print ('F1-score = {0}'.format(f1_score))\n",
    "    print ('Precision = {0}'.format(precision))\n",
    "    print ('Recall = {0}'.format(recall))\n",
    "    return(analysis.get_best_config(metric='keras_info/acc', mode='max'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 8.7/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/3 CPUs, 0/0 GPUs, 0.0/4.64 GiB heap, 0.0/1.56 GiB objects<br>Result logdir: /root/ray_results/Random_mnist_task4<br>Number of trials: 10/10 (10 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">        lr</th><th style=\"text-align: right;\">   unit</th><th style=\"text-align: right;\">     acc</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">    f1_m</th><th style=\"text-align: right;\">  precision_m</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>tune_mnist_070a6_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.0201999</td><td style=\"text-align: right;\">0.00277963</td><td style=\"text-align: right;\">46.122 </td><td style=\"text-align: right;\">0.987427</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         12.7533</td><td style=\"text-align: right;\"> 0.0570034</td><td style=\"text-align: right;\">0.987479</td><td style=\"text-align: right;\">     0.98752 </td></tr>\n",
       "<tr><td>tune_mnist_070a6_00001</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.0800977</td><td style=\"text-align: right;\">0.0687419 </td><td style=\"text-align: right;\">34.6523</td><td style=\"text-align: right;\">0.865001</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         11.0569</td><td style=\"text-align: right;\"> 0.246032 </td><td style=\"text-align: right;\">0.865104</td><td style=\"text-align: right;\">     0.865104</td></tr>\n",
       "<tr><td>tune_mnist_070a6_00002</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.0274417</td><td style=\"text-align: right;\">0.0340264 </td><td style=\"text-align: right;\">35.5525</td><td style=\"text-align: right;\">0.95194 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         10.9895</td><td style=\"text-align: right;\"> 0.13159  </td><td style=\"text-align: right;\">0.951921</td><td style=\"text-align: right;\">     0.952318</td></tr>\n",
       "<tr><td>tune_mnist_070a6_00003</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.123244 </td><td style=\"text-align: right;\">0.00237379</td><td style=\"text-align: right;\">22.4222</td><td style=\"text-align: right;\">0.978741</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         10.7936</td><td style=\"text-align: right;\"> 0.0587078</td><td style=\"text-align: right;\">0.97874 </td><td style=\"text-align: right;\">     0.97874 </td></tr>\n",
       "<tr><td>tune_mnist_070a6_00004</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.199422 </td><td style=\"text-align: right;\">0.00763165</td><td style=\"text-align: right;\">24.7493</td><td style=\"text-align: right;\">0.9775  </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         10.3745</td><td style=\"text-align: right;\"> 0.0525128</td><td style=\"text-align: right;\">0.97749 </td><td style=\"text-align: right;\">     0.97749 </td></tr>\n",
       "<tr><td>tune_mnist_070a6_00005</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.0273745</td><td style=\"text-align: right;\">0.00353324</td><td style=\"text-align: right;\">32.4271</td><td style=\"text-align: right;\">0.982794</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         11.4658</td><td style=\"text-align: right;\"> 0.0400779</td><td style=\"text-align: right;\">0.9828  </td><td style=\"text-align: right;\">     0.9828  </td></tr>\n",
       "<tr><td>tune_mnist_070a6_00006</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.0769428</td><td style=\"text-align: right;\">0.0180957 </td><td style=\"text-align: right;\">37.3951</td><td style=\"text-align: right;\">0.972537</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         12.0026</td><td style=\"text-align: right;\"> 0.0643474</td><td style=\"text-align: right;\">0.972498</td><td style=\"text-align: right;\">     0.972621</td></tr>\n",
       "<tr><td>tune_mnist_070a6_00007</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.0236908</td><td style=\"text-align: right;\">0.00340125</td><td style=\"text-align: right;\">28.5406</td><td style=\"text-align: right;\">0.984118</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         10.9394</td><td style=\"text-align: right;\"> 0.037716 </td><td style=\"text-align: right;\">0.984122</td><td style=\"text-align: right;\">     0.984122</td></tr>\n",
       "<tr><td>tune_mnist_070a6_00008</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.0175643</td><td style=\"text-align: right;\">0.00451989</td><td style=\"text-align: right;\">24.3249</td><td style=\"text-align: right;\">0.980065</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         10.52  </td><td style=\"text-align: right;\"> 0.048732 </td><td style=\"text-align: right;\">0.980091</td><td style=\"text-align: right;\">     0.980214</td></tr>\n",
       "<tr><td>tune_mnist_070a6_00009</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.0189807</td><td style=\"text-align: right;\">0.0846956 </td><td style=\"text-align: right;\">48.8068</td><td style=\"text-align: right;\">0.571677</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         11.2805</td><td style=\"text-align: right;\"> 0.583765 </td><td style=\"text-align: right;\">0.56968 </td><td style=\"text-align: right;\">     0.571962</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-06 10:41:09,979\tINFO tune.py:439 -- Total run time: 57.33 seconds (57.22 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can use any of the following columns to get the best model: \n",
      "['keras_info/loss', 'keras_info/acc', 'keras_info/f1_m', 'keras_info/precision_m', 'keras_info/recall_m', 'keras_info/val_loss', 'keras_info/val_acc', 'keras_info/val_f1_m', 'keras_info/val_precision_m', 'keras_info/val_recall_m'].\n",
      "==========\n",
      "Best model: tune_mnist_070a6_00007 lr: 0.0034012474960852393 unit: 28.540576419240914 dropout: 0.023690843765683638\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "RNN (SimpleRNN)              (None, 28)                1596      \n",
      "_________________________________________________________________\n",
      "dense_output (Dense)         (None, 10)                290       \n",
      "=================================================================\n",
      "Total params: 1,886\n",
      "Trainable params: 1,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Loss is 0.0385\n",
      "Tuned accuracy is 0.9878\n",
      "F1-score = 0.9876803159713745\n",
      "Precision = 0.9876803159713745\n",
      "Recall = 0.9876803159713745\n",
      "Train on 12089 samples, validate on 2042 samples\n",
      "Epoch 1/10\n",
      "12089/12089 [==============================] - 9s 706us/sample - loss: 1.1929 - acc: 0.6330 - f1_m: 0.6104 - precision_m: 0.6344 - recall_m: 0.6056 - val_loss: 0.1629 - val_acc: 0.9334 - val_f1_m: 0.9334 - val_precision_m: 0.9334 - val_recall_m: 0.9334\n",
      "Epoch 2/10\n",
      "12089/12089 [==============================] - 4s 369us/sample - loss: 0.1400 - acc: 0.9483 - f1_m: 0.9486 - precision_m: 0.9488 - recall_m: 0.9484 - val_loss: 0.1054 - val_acc: 0.9584 - val_f1_m: 0.9584 - val_precision_m: 0.9584 - val_recall_m: 0.9584\n",
      "Epoch 3/10\n",
      "12089/12089 [==============================] - 4s 367us/sample - loss: 0.0974 - acc: 0.9660 - f1_m: 0.9658 - precision_m: 0.9660 - recall_m: 0.9657 - val_loss: 0.0921 - val_acc: 0.9682 - val_f1_m: 0.9681 - val_precision_m: 0.9681 - val_recall_m: 0.9681\n",
      "Epoch 4/10\n",
      "12089/12089 [==============================] - 4s 368us/sample - loss: 0.0851 - acc: 0.9715 - f1_m: 0.9716 - precision_m: 0.9717 - recall_m: 0.9714 - val_loss: 0.0695 - val_acc: 0.9750 - val_f1_m: 0.9750 - val_precision_m: 0.9750 - val_recall_m: 0.9750\n",
      "Epoch 5/10\n",
      "12089/12089 [==============================] - 4s 369us/sample - loss: 0.0668 - acc: 0.9782 - f1_m: 0.9780 - precision_m: 0.9781 - recall_m: 0.9779 - val_loss: 0.0385 - val_acc: 0.9878 - val_f1_m: 0.9878 - val_precision_m: 0.9878 - val_recall_m: 0.9878\n",
      "Epoch 6/10\n",
      "12089/12089 [==============================] - 4s 366us/sample - loss: 0.0590 - acc: 0.9807 - f1_m: 0.9810 - precision_m: 0.9811 - recall_m: 0.9808 - val_loss: 0.0495 - val_acc: 0.9833 - val_f1_m: 0.9825 - val_precision_m: 0.9837 - val_recall_m: 0.9813\n",
      "Epoch 7/10\n",
      "12089/12089 [==============================] - 4s 368us/sample - loss: 0.0517 - acc: 0.9825 - f1_m: 0.9827 - precision_m: 0.9830 - recall_m: 0.9824 - val_loss: 0.0531 - val_acc: 0.9794 - val_f1_m: 0.9794 - val_precision_m: 0.9794 - val_recall_m: 0.9794\n",
      "Epoch 8/10\n",
      "12089/12089 [==============================] - 5s 373us/sample - loss: 0.0493 - acc: 0.9852 - f1_m: 0.9852 - precision_m: 0.9855 - recall_m: 0.9848 - val_loss: 0.0313 - val_acc: 0.9882 - val_f1_m: 0.9885 - val_precision_m: 0.9887 - val_recall_m: 0.9883\n",
      "Epoch 9/10\n",
      "12089/12089 [==============================] - 4s 365us/sample - loss: 0.0409 - acc: 0.9869 - f1_m: 0.9870 - precision_m: 0.9871 - recall_m: 0.9868 - val_loss: 0.0249 - val_acc: 0.9902 - val_f1_m: 0.9902 - val_precision_m: 0.9902 - val_recall_m: 0.9902\n",
      "Epoch 10/10\n",
      "12089/12089 [==============================] - 4s 369us/sample - loss: 0.0363 - acc: 0.9892 - f1_m: 0.9893 - precision_m: 0.9895 - recall_m: 0.9891 - val_loss: 0.0256 - val_acc: 0.9922 - val_f1_m: 0.9919 - val_precision_m: 0.9922 - val_recall_m: 0.9917\n",
      "Search algorithm random_search took 701.7413969039917.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pdb\n",
    "import time\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        last_model_stats = Model_Perf_save\n",
    "        for i,lay in enumerate(model.layers):\n",
    "            last_model_size = last_model_stats['shape'][-1][2*i+1][0]\n",
    "            layer_weights = lay.get_weights()\n",
    "            layer_weights[0][:last_model_stats['weights'][-1][3*i].shape[0],:last_model_size] = last_model_stats['weights'][-1][3*i]\n",
    "            if i != len(model.layers)-1: #for last (dense) layer\n",
    "                layer_weights[1][:last_model_stats['weights'][-1][3*i+1].shape[0],:last_model_size] = last_model_stats['weights'][-1][3*i+1]\n",
    "                layer_weights[2][:last_model_size] = last_model_stats['weights'][-1][3*i+2]\n",
    "            else:\n",
    "                layer_weights[1][:last_model_size] = last_model_stats['weights'][-1][3*i+1]\n",
    "            model.layers[i].set_weights(layer_weights)      \n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        last_model_stats = Model_Perf_save\n",
    "        for i,lay in enumerate(model.layers):\n",
    "            last_model_size = last_model_stats['shape'][-1][2*i+1][0]\n",
    "            layer_weights = lay.get_weights()\n",
    "            layer_weights[0][:last_model_stats['weights'][-1][3*i].shape[0],:last_model_size] = last_model_stats['weights'][-1][3*i]\n",
    "            if i != len(model.layers)-1: #for last (dense) layer\n",
    "                layer_weights[1][:last_model_stats['weights'][-1][3*i+1].shape[0],:last_model_size] = last_model_stats['weights'][-1][3*i+1]\n",
    "                layer_weights[2][:last_model_size] = last_model_stats['weights'][-1][3*i+2]\n",
    "            else:\n",
    "                layer_weights[1][:last_model_size] = last_model_stats['weights'][-1][3*i+1]\n",
    "            model.layers[i].set_weights(layer_weights)  \n",
    "        \n",
    "def create_task(data_path):\n",
    "    data = pickle.load(open(data_path, \"rb\"))\n",
    "    return data\n",
    "\n",
    "def measure_CPU_Mem():\n",
    "    import psutil\n",
    "    CPU_usage_dump = []\n",
    "    Mem_usage_dump = []  \n",
    "    while True:\n",
    "        CPU_usage_dump.append(psutil.cpu_percent())\n",
    "        Mem_usage_dump.append(psutil.virtual_memory().percent)\n",
    "        f_cpu=open(\"CPU_used.txt\", \"wb\")\n",
    "        f_mem=open(\"Mem_used.txt\", \"wb\")\n",
    "        pickle.dump(CPU_usage_dump, f_cpu) \n",
    "        pickle.dump(Mem_usage_dump, f_mem)     \n",
    "        f_cpu.close()\n",
    "        f_mem.close()\n",
    "        time.sleep(1)\n",
    "\n",
    "import multiprocessing\n",
    "task_list = create_task('mnist_tasks.pkl')\n",
    "num_tasks=5\n",
    "num_labels=10\n",
    "Model_Perf_save = {}\n",
    "Model_Perf_save['tr_acc'] = []\n",
    "Model_Perf_save['val_acc'] = []\n",
    "Model_Perf_save['precision'] = []\n",
    "Model_Perf_save['recall'] = []\n",
    "Model_Perf_save['f1_score'] = []\n",
    "Model_Perf_save['shape'] = []\n",
    "Model_Perf_save['weights'] = []\n",
    "Model_Perf_save['learn_rate'] = []\n",
    "cpu_resouce_fed = 3\n",
    "for search_algo in [ \n",
    "                    random_search,\n",
    "                    #ASHA_search,\n",
    "                    #mutation_pbtsearch,\n",
    "                    #BayesOptSearch,\n",
    "                    #NeverGradSearch,\n",
    "                    #OptunaSearch,\n",
    "                    #ZOOptSearch,\n",
    "                    #hyperopt_search\n",
    "                    ]:\n",
    "    cpu_mem_collection = multiprocessing.Process(target=measure_CPU_Mem)\n",
    "    cpu_mem_collection.start()\n",
    "    start_time = time.time()\n",
    "    for task_id in range(0,num_tasks):\n",
    "        !rm -rf task_dataset.pkl\n",
    "        f = open('task_dataset.pkl', 'wb')\n",
    "        pickle.dump(task_list[task_id], f)\n",
    "        f.close()\n",
    "        hyper_param = search_algo(task_list[task_id], task_id, cpu_resouce_fed)\n",
    "        image_size = 28\n",
    "        if task_id == 0:\n",
    "            model = create_model(learning_rate=hyper_param['lr'], RNN_units=int(hyper_param['unit']), dropout=hyper_param['dropout'])\n",
    "            #call one of the search algorithm\n",
    "            history = model.fit(np.reshape(task_list[task_id][0],[-1, image_size, image_size]), \n",
    "                  task_list[task_id][1], batch_size=128, epochs=10, verbose=1,\n",
    "                  validation_data=(np.reshape(task_list[task_id][2],[-1, image_size, image_size]), task_list[task_id][3]))\n",
    "        else:\n",
    "            rnn_units = hyper_param[\"unit\"] + Model_Perf_save['shape'][-1][1][0]\n",
    "            model = create_model(learning_rate=hyper_param['lr'], RNN_units=int(rnn_units), dropout=hyper_param['dropout'])\n",
    "            history = model.fit(np.reshape(task_list[task_id][0],[-1, image_size, image_size]),\n",
    "                  task_list[task_id][1], batch_size=128, epochs=10, verbose=1,\n",
    "                  validation_data=(np.reshape(task_list[task_id][2],[-1, image_size, image_size]), task_list[task_id][3]), callbacks  = [LossHistory()])\n",
    "        loss_and_metrics = model.evaluate(np.reshape(task_list[task_id][0],[-1, image_size, image_size]), task_list[task_id][1], verbose=0)\n",
    "        Model_Perf_save['tr_acc'].append(loss_and_metrics[1])\n",
    "        loss_and_metrics = model.evaluate(np.reshape(task_list[task_id][4],[-1, image_size, image_size]), task_list[task_id][5], verbose=0)\n",
    "        Model_Perf_save['val_acc'].append(loss_and_metrics[1])\n",
    "        Model_Perf_save['f1_score'].append(loss_and_metrics[2])\n",
    "        Model_Perf_save['precision'].append(loss_and_metrics[3])\n",
    "        Model_Perf_save['recall'].append(loss_and_metrics[4])\n",
    "        Model_Perf_save['shape'].append([i.shape for i in model.get_weights()])\n",
    "        Model_Perf_save['learn_rate'].append(hyper_param[\"lr\"])\n",
    "        Model_Perf_save['weights'].append(model.get_weights()) \n",
    "    end_time = time.time()\n",
    "    print('Search algorithm {} took {}.'.format(search_algo.__name__, end_time - start_time))\n",
    "    \n",
    "    f=open(\"time_taken.txt\", \"a+\")\n",
    "    f.write('Time taken for algo {} is {}. \\n'.format(search_algo.__name__, end_time-start_time))\n",
    "\n",
    "    try:\n",
    "        f_cpu=open(\"CPU_used.txt\", \"rb\")\n",
    "        f_mem=open(\"Mem_used.txt\", \"rb\")\n",
    "        cpu_usage = pickle.load(f_cpu)\n",
    "        mem_usage = pickle.load(f_mem)\n",
    "        f_cpu.close()\n",
    "        f_mem.close()\n",
    "        cpu_mem_collection.terminate()\n",
    "        cpu_mem_collection.join()\n",
    "        f.write('CPU used is {}. \\n'.format(np.mean(cpu_usage)))\n",
    "        f.write('Memory used is {}. \\n \\n'.format(np.mean(mem_usage)))\n",
    "        f.close()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Algorithm: random_search\n",
      "Training accuracy for tasks: [0.99881566, 0.9970701, 0.9990971, 0.99389833, 0.99222434]\n",
      "Validation accuracy for tasks: [0.9962175, 0.9973319, 0.9979859, 0.9939486, 0.99216455]\n",
      "Precision: [0.99626863, 0.9969397, 0.9980159, 0.9939516, 0.9921875]\n",
      "Recall: [0.99626863, 0.9969397, 0.9980159, 0.9939516, 0.9916992]\n",
      "F1 score: [0.99626863, 0.9969397, 0.9980159, 0.9939516, 0.9919395]\n",
      "Nodes in hidden layer:  [(28, 32), (28, 64), (28, 110), (28, 156), (28, 202)]\n",
      "Learning rates:  [0.0035332382550846446, 0.0035332382550846446, 0.002779625851893939, 0.002779625851893939, 0.002779625851893939]\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for j,search_algo in enumerate([\n",
    "                    #ASHA_search, \n",
    "                    random_search,\n",
    "                    #mutation_pbtsearch,\n",
    "                    #BayesOptSearch,\n",
    "                    #NeverGradSearch,\n",
    "                    #OptunaSearch,\n",
    "                    #ZOOptSearch,\n",
    "                    #hyperopt_search\n",
    "                    ]):\n",
    "    print('Search Algorithm: {0}'.format(search_algo.__name__))\n",
    "    print('Training accuracy for tasks:',Model_Perf_save['tr_acc'][j*num_tasks:j*num_tasks+num_tasks])\n",
    "    print('Validation accuracy for tasks:',Model_Perf_save['val_acc'][j*num_tasks:j*num_tasks+num_tasks])\n",
    "    print('Precision:',Model_Perf_save['precision'][j*num_tasks:j*num_tasks+num_tasks])\n",
    "    print('Recall:',Model_Perf_save['recall'][j*num_tasks:j*num_tasks+num_tasks])\n",
    "    print('F1 score:',Model_Perf_save['f1_score'][j*num_tasks:j*num_tasks+num_tasks])\n",
    "    print('Nodes in hidden layer: ',[(i[0])for i in Model_Perf_save['shape']][j*num_tasks:j*num_tasks+num_tasks])\n",
    "    print('Learning rates: ', Model_Perf_save['learn_rate'][j*num_tasks:j*num_tasks+num_tasks])\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.025618267930628155, 0.99216455, 0.9919395, 0.9921875, 0.9916992]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# later...\n",
    " \n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "optimizer = Adam(clipvalue=0.5)\n",
    "loaded_model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy',f1_m,precision_m, recall_m])\n",
    "loaded_model.evaluate(np.reshape(task_list[task_id][4],[-1, image_size, image_size]), task_list[task_id][5], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.43884821596622, 0.021057786, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_id=4\n",
    "current_stage_weights = Model_Perf_save['weights'][-1].copy()\n",
    "select_task_shape = Model_Perf_save['shape'][task_id]\n",
    "for j,weight_size in enumerate(select_task_shape):\n",
    "    if len(weight_size) == 2:\n",
    "        current_stage_weights[j][weight_size[0]:,weight_size[1]:]=0\n",
    "    else:\n",
    "        current_stage_weights[j][weight_size[0]:]=0\n",
    "loaded_model.set_weights(current_stage_weights)\n",
    "loaded_model.evaluate(np.reshape(task_list[task_id][4],[-1, image_size, image_size]), task_list[task_id][5], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.43884821596622, 0.021057786, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.set_weights(Model_Perf_save['weights'][-1])\n",
    "loaded_model.evaluate(np.reshape(task_list[task_id][4],[-1, image_size, image_size]), task_list[task_id][5], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (array([], dtype=int64), array([], dtype=int64))\n",
      "1 (array([], dtype=int64), array([], dtype=int64))\n",
      "2 (array([], dtype=int64),)\n",
      "3 (array([], dtype=int64), array([], dtype=int64))\n",
      "4 (array([], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(loaded_model.get_weights()):\n",
    "    comparision_result = j == Model_Perf_save['weights'][-1][i]\n",
    "    print(i, np.where(comparision_result == False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

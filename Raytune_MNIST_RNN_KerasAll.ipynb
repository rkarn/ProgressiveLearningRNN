{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "from ray.tune import track\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "try:\n",
    "    tf.get_logger().setLevel('INFO')\n",
    "except Exception as exc:\n",
    "    print(exc)\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "import ray\n",
    "from ray import tune\n",
    "import time\n",
    "import inspect\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "'''\n",
    "class TuneReporterCallback(keras.callbacks.Callback):\n",
    "    \"\"\"Tune Callback for Keras.\n",
    "    \n",
    "    The callback is invoked every epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, logs={}):\n",
    "        self.iteration = 0\n",
    "        super(TuneReporterCallback, self).__init__()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.iteration += 1\n",
    "        track.log(keras_info=logs, mean_accuracy=logs.get(\"accuracy\"), mean_loss=logs.get(\"loss\"))\n",
    "    \n",
    "'''   \n",
    "class TuneReporterCallback(keras.callbacks.Callback):\n",
    "    \"\"\"Tune Callback for Keras.\n",
    "    \n",
    "    The callback is invoked every epoch.\n",
    "    \"\"\"\n",
    "    def __init__(self, logs={}):\n",
    "        self.iteration = 0\n",
    "        super(TuneReporterCallback, self).__init__()\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.iteration += 1\n",
    "        if \"acc\" in logs:\n",
    "            tune.report(keras_info=logs, val_loss=logs['val_loss'], mean_accuracy=logs[\"acc\"], f1_m = logs['f1_m'], precision_m=logs['precision_m'], recall_m=logs['recall_m'])\n",
    "        else:\n",
    "            tune.report(keras_info=logs, val_loss=logs['val_loss'], mean_accuracy=logs.get(\"accuracy\"), f1_m = logs.get('f1_m'), precision_m=logs.get('precision_m'), recall_m=logs.get('recall_m'))\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "from keras import backend as K\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))        \n",
    "        \n",
    "def create_model(learning_rate, RNN_units, dropout):\n",
    "    assert learning_rate > 0 and RNN_units > 0 and dropout > 0, \"Did you set the right configuration?\"\n",
    "    input_shape = (28, 28)\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(units=int(RNN_units), dropout=dropout, input_shape=input_shape,  activation='relu', name='RNN'))\n",
    "    model.add(Dense(num_labels, activation = 'softmax', name = 'dense_output'))\n",
    "    #optimizer = SGD(lr=learning_rate)\n",
    "    optimizer = Adam(clipvalue=0.5, lr=learning_rate)\n",
    "    model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy',f1_m,precision_m, recall_m])\n",
    "    return model\n",
    "        \n",
    "def tune_mnist(config):  \n",
    "    model = create_model(learning_rate=config['lr'], RNN_units=int(config['unit']), dropout=config['dropout'])  # TODO: Change me.\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        \"model.h5\", monitor='loss', save_best_only=True, save_freq=2)\n",
    "\n",
    "    # Enable Tune to make intermediate decisions by using a Tune Callback hook. This is Keras specific.\n",
    "    callbacks = [checkpoint_callback, TuneReporterCallback()]\n",
    "    task_dataset = pickle.load(open('/root/Raytune_MNIST_RNN/task_dataset.pkl', \"rb\"))\n",
    "    image_size = 28\n",
    "    X_train = np.reshape(task_dataset[0],[-1, image_size, image_size]) \n",
    "    Y_train = task_dataset[1]\n",
    "    X_test = np.reshape(task_dataset[2],[-1, image_size, image_size]) \n",
    "    Y_test = task_dataset[3]\n",
    "    # Train the model\n",
    "    hist = model.fit(\n",
    "        X_train, Y_train, \n",
    "        validation_data=(X_test, Y_test),\n",
    "        verbose=0, \n",
    "        batch_size=100, \n",
    "        epochs=10, \n",
    "        callbacks=callbacks)\n",
    "    for key in hist.history:\n",
    "        print(key)\n",
    "\n",
    "# Random and uniform sampling for hypertune\n",
    "def random_search(task_data, task_id=0, cpu_resouce_fed=4):\n",
    "    import numpy as np; np.random.seed(5)  \n",
    "    hyperparameter_space = {\n",
    "        \"lr\": tune.loguniform(0.001, 0.1),  \n",
    "        \"unit\": tune.uniform(20, 50),\n",
    "        \"dropout\": tune.loguniform(0.01, 0.3),\n",
    "    }  \n",
    "    num_samples = 10 \n",
    "    ####################################################################################################\n",
    "    ################ This is just a validation function for tutorial purposes only. ####################\n",
    "    HP_KEYS = [\"lr\", \"unit\", \"dropout\"]\n",
    "    assert all(key in hyperparameter_space for key in HP_KEYS), (\n",
    "        \"The hyperparameter space is not fully designated. It must include all of {}\".format(HP_KEYS))\n",
    "    ######################################################################################################\n",
    "\n",
    "    ray.shutdown()  # Restart Ray defensively in case the ray connection is lost. \n",
    "    ray.init(log_to_driver=False, num_cpus=cpu_resouce_fed)\n",
    "    # We clean out the logs before running for a clean visualization later.\n",
    "    ! rm -rf ~/ray_results/tune_mnist$task_id\n",
    "    analysis = tune.run(\n",
    "        tune_mnist, \n",
    "        name=\"Random_mnist_task\"+str(task_id),\n",
    "        verbose=1, \n",
    "        config=hyperparameter_space,\n",
    "        num_samples=num_samples)\n",
    "    time.sleep(1)\n",
    "\n",
    "    assert len(analysis.trials) > 2, \"Did you set the correct number of samples?\"\n",
    "\n",
    "    # Obtain the directory where the best model is saved.\n",
    "    print(\"You can use any of the following columns to get the best model: \\n{}.\".format(\n",
    "        [k for k in analysis.dataframe() if k.startswith(\"keras_info\")]))\n",
    "    print(\"=\" * 10)\n",
    "    logdir = analysis.get_best_logdir(\"keras_info/val_acc\", mode=\"max\")\n",
    "    print('Best model:',analysis.get_best_trial(metric='keras_info/val_acc', mode='max'), \n",
    "          'lr:', analysis.get_best_config(metric='keras_info/val_acc', mode='max')['lr'], 'unit:', analysis.get_best_config(metric='keras_info/val_acc', mode='max')['unit'], 'dropout:', analysis.get_best_config(metric='keras_info/val_acc', mode='max')['dropout'] )\n",
    "    # We saved the model as `model.h5` in the logdir of the trial.\n",
    "    from tensorflow.keras.models import load_model\n",
    "    tuned_model = load_model(logdir + \"/model.h5\", custom_objects =  {'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m})\n",
    "    tuned_model.summary()\n",
    "    image_size = 28\n",
    "    X_test = np.reshape(task_data[2],[-1, image_size, image_size])  \n",
    "    Y_test = task_data[3]\n",
    "    tuned_loss, tuned_accuracy, f1_score, precision, recall = tuned_model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print(\"Loss is {:0.4f}\".format(tuned_loss))\n",
    "    print(\"Tuned accuracy is {:0.4f}\".format(tuned_accuracy))\n",
    "    print ('F1-score = {0}'.format(f1_score))\n",
    "    print ('Precision = {0}'.format(precision))\n",
    "    print ('Recall = {0}'.format(recall))\n",
    "    return(analysis.get_best_config(metric='keras_info/acc', mode='max'))\n",
    "\n",
    "#PBT population based sampling \n",
    "def mutation_pbtsearch(task_data, task_id=0, cpu_resouce_fed=4):\n",
    "    from ray.tune.schedulers import PopulationBasedTraining\n",
    "    from ray.tune.utils import validate_save_restore\n",
    "    scheduler = PopulationBasedTraining(\n",
    "        time_attr=\"training_iteration\",\n",
    "        metric=\"mean_accuracy\",\n",
    "        mode=\"max\",\n",
    "        perturbation_interval=20,\n",
    "        hyperparam_mutations={\n",
    "            # distribution for resampling\n",
    "            \"lr\": lambda: np.random.uniform(0.0001, 1),\n",
    "            # allow perturbations within this set of categorical values\n",
    "            \"unit\": [40, 60, 100], \"dropout\": [0.1, 0.2, 0.3], \n",
    "        }\n",
    "    )\n",
    "\n",
    "    old_dirs = os.listdir('/root/ray_results/')\n",
    "\n",
    "    ray.shutdown()  # Restart Ray defensively in case the ray connection is lost. \n",
    "    ray.init(log_to_driver=False, num_cpus=cpu_resouce_fed)\n",
    "    ! rm -rf ~/ray_results/PBT_mnist_task$task_id\n",
    "    analysis = tune.run(\n",
    "        tune_mnist,\n",
    "        name=\"PBT_mnist_task\"+str(task_id),\n",
    "        scheduler=scheduler,\n",
    "        reuse_actors=True,\n",
    "        verbose=1,\n",
    "        stop={\n",
    "            \"training_iteration\": 100,\n",
    "        },\n",
    "        num_samples=10,\n",
    "\n",
    "        # PBT starts by training many neural networks in parallel with random hyperparameters. \n",
    "        config={\n",
    "        \"lr\": tune.loguniform(0.001, 0.1),  \n",
    "        \"unit\": tune.uniform(20, 50),\n",
    "        \"dropout\": tune.loguniform(0.01, 0.3),\n",
    "    } )\n",
    "    time.sleep(1)\n",
    "    print(\"You can use any of the following columns to get the best model: \\n{}.\".format(\n",
    "        [k for k in analysis.dataframe() if k.startswith(\"keras_info\")]))\n",
    "    print(\"=\" * 10)\n",
    "    logdir = analysis.get_best_logdir(\"keras_info/val_acc\", mode=\"max\")\n",
    "    print('Best model:',analysis.get_best_trial(metric='keras_info/val_acc', mode='max'), \n",
    "          analysis.get_best_config(metric='keras_info/val_acc', mode='max'))\n",
    "    # We saved the model as `model.h5` in the logdir of the trial.\n",
    "    from tensorflow.keras.models import load_model\n",
    "    tuned_model = load_model(logdir + \"/model.h5\", custom_objects =  {'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m})\n",
    "    tuned_model.summary()\n",
    "    image_size = 28\n",
    "    X_test = np.reshape(task_data[2],[-1, image_size, image_size])\n",
    "    Y_test = task_data[3]\n",
    "    tuned_loss, tuned_accuracy, f1_score, precision, recall = tuned_model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print(\"Loss is {:0.4f}\".format(tuned_loss))\n",
    "    print(\"Tuned accuracy is {:0.4f}\".format(tuned_accuracy))\n",
    "    print ('F1-score = {0}'.format(f1_score))\n",
    "    print ('Precision = {0}'.format(precision))\n",
    "    print ('Recall = {0}'.format(recall))\n",
    "    return(analysis.get_best_config(metric='keras_info/acc', mode='max'))\n",
    "\n",
    "#ASHA Schedular\n",
    "def ASHA_search(task_data, task_id=0, cpu_resouce_fed=4):\n",
    "    from ray.tune.schedulers import ASHAScheduler\n",
    "    ray.shutdown()  # Restart Ray defensively in case the ray connection is lost. \n",
    "    ray.init(log_to_driver=False, num_cpus=cpu_resouce_fed)\n",
    "    custom_scheduler = ASHAScheduler(\n",
    "        metric='mean_accuracy',\n",
    "        mode=\"max\",\n",
    "        reduction_factor = 4,\n",
    "        grace_period=1)# TODO: Add a ASHA as custom scheduler here\n",
    "    hyperparameter_space={\n",
    "        \"lr\": tune.loguniform(0.001, 0.1),  \n",
    "        \"unit\": tune.uniform(20, 50),\n",
    "        \"dropout\": tune.loguniform(0.01, 0.3),\n",
    "    } \n",
    "    ray.shutdown()  # Restart Ray defensively in case the ray connection is lost. \n",
    "    ray.init(log_to_driver=False, num_cpus=cpu_resouce_fed)\n",
    "    ! rm -rf ~/ray_results/ASHA_mnist_task$task_id\n",
    "    analysis = tune.run(\n",
    "        tune_mnist, \n",
    "        scheduler=custom_scheduler, \n",
    "        config=hyperparameter_space, \n",
    "        verbose=1,\n",
    "        num_samples=10,\n",
    "        #resources_per_trial={\"cpu\":4},\n",
    "        name=\"ASHA_mnist_task\"+str(task_id)  # This is used to specify the logging directory.\n",
    "    )\n",
    "    time.sleep(1)\n",
    "    print(\"You can use any of the following columns to get the best model: \\n{}.\".format(\n",
    "        [k for k in analysis.dataframe() if k.startswith(\"keras_info\")]))\n",
    "    print(\"=\" * 10)\n",
    "    logdir = analysis.get_best_logdir(\"keras_info/acc\", mode=\"max\")\n",
    "    print('Best model:',analysis.get_best_trial(metric='keras_info/acc', mode='max'), \n",
    "          analysis.get_best_config(metric='keras_info/acc', mode='max'))\n",
    "    # We saved the model as `model.h5` in the logdir of the trial.\n",
    "    from tensorflow.keras.models import load_model\n",
    "    tuned_model = load_model(logdir + \"/model.h5\", custom_objects =  {'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m})\n",
    "    tuned_model.summary()\n",
    "    image_size = 28\n",
    "    X_test = np.reshape(task_data[2],[-1, image_size, image_size])\n",
    "    Y_test = task_data[3]\n",
    "    tuned_loss, tuned_accuracy, f1_score, precision, recall = tuned_model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print(\"Loss is {:0.4f}\".format(tuned_loss))\n",
    "    print(\"Tuned accuracy is {:0.4f}\".format(tuned_accuracy))\n",
    "    print ('F1-score = {0}'.format(f1_score))\n",
    "    print ('Precision = {0}'.format(precision))\n",
    "    print ('Recall = {0}'.format(recall))\n",
    "    return(analysis.get_best_config(metric='keras_info/acc', mode='max'))\n",
    "\n",
    "\n",
    "#HyperOpt Search \n",
    "def hyperopt_search(task_data, task_id=0, cpu_resouce_fed=4):\n",
    "    from ray.tune.suggest import ConcurrencyLimiter\n",
    "    from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "    from ray.tune.suggest.hyperopt import HyperOptSearch\n",
    "\n",
    "    \n",
    "    search_space={\n",
    "        \"lr\": tune.loguniform(0.001, 0.1),  \n",
    "        \"unit\": tune.uniform(20, 50),\n",
    "        \"dropout\": tune.loguniform(0.01, 0.3),\n",
    "    }\n",
    "    current_best_params = [{\n",
    "    'lr': 0.01,\n",
    "    'unit': 25,\n",
    "    'dropout': 0.2,\n",
    "    }]\n",
    "    scheduler = AsyncHyperBandScheduler()\n",
    "    \n",
    "    algo = HyperOptSearch(points_to_evaluate=current_best_params)\n",
    "    algo = ConcurrencyLimiter(algo, max_concurrent=cpu_resouce_fed)\n",
    "    ray.shutdown()  # Restart Ray defensively in case the ray connection is lost. \n",
    "    ray.init(log_to_driver=False, num_cpus=cpu_resouce_fed)\n",
    "    ! rm -rf ~/ray_results/BayesOptSearch_mnist_task$task_id\n",
    "    analysis =tune.run(tune_Drebin,\n",
    "        name=\"hyperopt_mnist_task\"+str(task_id), verbose = 1,\n",
    "        scheduler=scheduler,\n",
    "        search_alg=algo,\n",
    "        num_samples=10, \n",
    "        metric=\"mean_accuracy\",\n",
    "        mode=\"max\",\n",
    "        config=search_space,\n",
    "        stop={\"training_iteration\": 150})\n",
    "    time.sleep(1)\n",
    "    #from ray.tune import Analysis as analysis\n",
    "    #analysis = ray.tune.Analysis('/root/ray_results/BayesOptSearch_ASNM') \n",
    "    print(\"You can use any of the following columns to get the best model: \\n{}.\".format(\n",
    "        [k for k in analysis.dataframe() if k.startswith(\"keras_info\")]))\n",
    "    print(\"=\" * 10)\n",
    "    logdir = analysis.get_best_logdir(\"keras_info/acc\", mode=\"max\")\n",
    "    print('Best model:', analysis.get_best_config(metric='keras_info/acc', mode='max'))\n",
    "    # We saved the model as `model.h5` in the logdir of the trial.\n",
    "    from tensorflow.keras.models import load_model\n",
    "    tuned_model = load_model(logdir + \"/model.h5\", custom_objects =  {'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m})\n",
    "    tuned_model.summary()\n",
    "    image_size = 28\n",
    "    X_test = np.reshape(task_data[2],[-1, image_size, image_size])\n",
    "    Y_test = task_data[3]\n",
    "    tuned_loss, tuned_accuracy, f1_score, precision, recall = tuned_model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print(\"Loss is {:0.4f}\".format(tuned_loss))\n",
    "    print(\"Tuned accuracy is {:0.4f}\".format(tuned_accuracy))\n",
    "    print ('F1-score = {0}'.format(f1_score))\n",
    "    print ('Precision = {0}'.format(precision))\n",
    "    print ('Recall = {0}'.format(recall))\n",
    "    return(analysis.get_best_config(metric='keras_info/acc', mode='max'))\n",
    "\n",
    "def BayesOptSearch(task_data, task_id=0, cpu_resouce_fed=4):\n",
    "    from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "    from ray.tune.suggest import ConcurrencyLimiter\n",
    "    from ray.tune.suggest.bayesopt import BayesOptSearch\n",
    "    \n",
    "    search_space={\n",
    "        \"lr\": tune.loguniform(0.001, 0.1),  \n",
    "        \"unit\": tune.uniform(20, 50),\n",
    "        \"dropout\": tune.loguniform(0.01, 0.3),\n",
    "    } \n",
    "    scheduler = AsyncHyperBandScheduler()\n",
    "    \n",
    "    algo = ConcurrencyLimiter(BayesOptSearch(utility_kwargs={\n",
    "        \"kind\": \"ucb\",\n",
    "        \"kappa\": 2.5,\n",
    "        \"xi\": 0.0\n",
    "        }, metric = 'mean_accuracy', mode = 'max'), \n",
    "        max_concurrent=cpu_resouce_fed)\n",
    "    ray.shutdown()  # Restart Ray defensively in case the ray connection is lost. \n",
    "    ray.init(log_to_driver=False, num_cpus=cpu_resouce_fed)\n",
    "    ! rm -rf ~/ray_results/BayesOptSearch_mnist_task$task_id\n",
    "    analysis =tune.run(tune_mnist,\n",
    "        name=\"BayesOptSearch_mnist_task\"+str(task_id), verbose = 1,\n",
    "        scheduler=scheduler,\n",
    "        search_alg=algo,\n",
    "        num_samples=100, \n",
    "        metric=\"mean_accuracy\",\n",
    "        mode=\"max\",\n",
    "        config=search_space,\n",
    "        stop={\"training_iteration\": 150})\n",
    "    time.sleep(1)\n",
    "    #from ray.tune import Analysis as analysis\n",
    "    #analysis = ray.tune.Analysis('/root/ray_results/BayesOptSearch_ASNM') \n",
    "    print(\"You can use any of the following columns to get the best model: \\n{}.\".format(\n",
    "        [k for k in analysis.dataframe() if k.startswith(\"keras_info\")]))\n",
    "    print(\"=\" * 10)\n",
    "    logdir = analysis.get_best_logdir(\"keras_info/acc\", mode=\"max\")\n",
    "    print('Best model:', analysis.get_best_config(metric='keras_info/acc', mode='max'))\n",
    "    # We saved the model as `model.h5` in the logdir of the trial.\n",
    "    from tensorflow.keras.models import load_model\n",
    "    tuned_model = load_model(logdir + \"/model.h5\", custom_objects =  {'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m})\n",
    "    tuned_model.summary()\n",
    "    image_size = 28\n",
    "    X_test = np.reshape(task_data[2],[-1, image_size, image_size])\n",
    "    Y_test = task_data[3]\n",
    "    tuned_loss, tuned_accuracy, f1_score, precision, recall = tuned_model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print(\"Loss is {:0.4f}\".format(tuned_loss))\n",
    "    print(\"Tuned accuracy is {:0.4f}\".format(tuned_accuracy))\n",
    "    print ('F1-score = {0}'.format(f1_score))\n",
    "    print ('Precision = {0}'.format(precision))\n",
    "    print ('Recall = {0}'.format(recall))\n",
    "    return(analysis.get_best_config(metric='keras_info/acc', mode='max'))\n",
    "\n",
    "\n",
    "def NeverGradSearch(task_data, task_id=0, cpu_resouce_fed=4):\n",
    "    from ray.tune.suggest import ConcurrencyLimiter\n",
    "    from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "    from ray.tune.suggest.nevergrad import NevergradSearch\n",
    "    import nevergrad as ng\n",
    "    \n",
    "    search_space={\n",
    "        \"lr\": tune.loguniform(0.001, 0.1),  \n",
    "        \"unit\": tune.uniform(20, 50),\n",
    "        \"dropout\": tune.loguniform(0.01, 0.3),\n",
    "    } \n",
    "    scheduler = AsyncHyperBandScheduler()\n",
    "    \n",
    "    algo = NevergradSearch(\n",
    "        optimizer=ng.optimizers.OnePlusOne,\n",
    "        # space=space,  # If you want to set the space manually\n",
    "    )\n",
    "    algo = ConcurrencyLimiter(algo, max_concurrent=cpu_resouce_fed)\n",
    "    ray.shutdown()  # Restart Ray defensively in case the ray connection is lost. \n",
    "    ray.init(log_to_driver=False, num_cpus=cpu_resouce_fed)\n",
    "    ! rm -rf ~/ray_results/BayesOptSearch_mnist_task$task_id\n",
    "    analysis =tune.run(tune_mnist,\n",
    "        name=\"NeverGradSearch_mnist_task\"+str(task_id), verbose = 1,\n",
    "        scheduler=scheduler,\n",
    "        search_alg=algo,\n",
    "        num_samples=10, \n",
    "        metric=\"mean_accuracy\",\n",
    "        mode=\"max\",\n",
    "        config=search_space,\n",
    "        stop={\"training_iteration\": 150})\n",
    "    time.sleep(1)\n",
    "    #from ray.tune import Analysis as analysis\n",
    "    #analysis = ray.tune.Analysis('/root/ray_results/BayesOptSearch_ASNM') \n",
    "    print(\"You can use any of the following columns to get the best model: \\n{}.\".format(\n",
    "        [k for k in analysis.dataframe() if k.startswith(\"keras_info\")]))\n",
    "    print(\"=\" * 10)\n",
    "    logdir = analysis.get_best_logdir(\"keras_info/acc\", mode=\"max\")\n",
    "    print('Best model:', analysis.get_best_config(metric='keras_info/acc', mode='max'))\n",
    "    # We saved the model as `model.h5` in the logdir of the trial.\n",
    "    from tensorflow.keras.models import load_model\n",
    "    tuned_model = load_model(logdir + \"/model.h5\", custom_objects =  {'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m})\n",
    "    tuned_model.summary()\n",
    "    image_size = 28\n",
    "    X_test = np.reshape(task_data[2],[-1, image_size, image_size])\n",
    "    Y_test = task_data[3]\n",
    "    tuned_loss, tuned_accuracy, f1_score, precision, recall = tuned_model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print(\"Loss is {:0.4f}\".format(tuned_loss))\n",
    "    print(\"Tuned accuracy is {:0.4f}\".format(tuned_accuracy))\n",
    "    print ('F1-score = {0}'.format(f1_score))\n",
    "    print ('Precision = {0}'.format(precision))\n",
    "    print ('Recall = {0}'.format(recall))\n",
    "    return(analysis.get_best_config(metric='keras_info/acc', mode='max'))\n",
    "\n",
    "def OptunaSearch(task_data, task_id=0, cpu_resouce_fed=4):\n",
    "    from ray.tune.suggest import ConcurrencyLimiter\n",
    "    from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "    from ray.tune.suggest.optuna import OptunaSearch\n",
    "    \n",
    "    search_space={\n",
    "        \"lr\": tune.loguniform(0.001, 0.1),  \n",
    "        \"unit\": tune.uniform(20, 50),\n",
    "        \"dropout\": tune.loguniform(0.01, 0.3),\n",
    "    } \n",
    "    scheduler = AsyncHyperBandScheduler()\n",
    "    \n",
    "    algo = OptunaSearch(metric=\"mean_accuracy\",\n",
    "        mode=\"max\")\n",
    "    algo = ConcurrencyLimiter(algo, max_concurrent=cpu_resouce_fed)\n",
    "    ray.shutdown()  # Restart Ray defensively in case the ray connection is lost. \n",
    "    ray.init(log_to_driver=False, num_cpus=cpu_resouce_fed)\n",
    "    ! rm -rf ~/ray_results/BayesOptSearch_mnist_task$task_id\n",
    "    analysis =tune.run(tune_mnist,\n",
    "        name=\"OptunaSearch_mnist_task\"+str(task_id), verbose = 1,\n",
    "        scheduler=scheduler,\n",
    "        search_alg=algo,\n",
    "        num_samples=10, \n",
    "        metric=\"mean_accuracy\",\n",
    "        mode=\"max\",\n",
    "        config=search_space,\n",
    "        stop={\"training_iteration\": 150})\n",
    "    time.sleep(1)\n",
    "    #from ray.tune import Analysis as analysis\n",
    "    #analysis = ray.tune.Analysis('/root/ray_results/BayesOptSearch_ASNM') \n",
    "    print(\"You can use any of the following columns to get the best model: \\n{}.\".format(\n",
    "        [k for k in analysis.dataframe() if k.startswith(\"keras_info\")]))\n",
    "    print(\"=\" * 10)\n",
    "    logdir = analysis.get_best_logdir(\"keras_info/acc\", mode=\"max\")\n",
    "    print('Best model:', analysis.get_best_config(metric='keras_info/acc', mode='max'))\n",
    "    # We saved the model as `model.h5` in the logdir of the trial.\n",
    "    from tensorflow.keras.models import load_model\n",
    "    tuned_model = load_model(logdir + \"/model.h5\", custom_objects =  {'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m})\n",
    "    tuned_model.summary()\n",
    "    image_size = 28\n",
    "    X_test = np.reshape(task_data[2],[-1, image_size, image_size])\n",
    "    Y_test = task_data[3]\n",
    "    tuned_loss, tuned_accuracy, f1_score, precision, recall = tuned_model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print(\"Loss is {:0.4f}\".format(tuned_loss))\n",
    "    print(\"Tuned accuracy is {:0.4f}\".format(tuned_accuracy))\n",
    "    print ('F1-score = {0}'.format(f1_score))\n",
    "    print ('Precision = {0}'.format(precision))\n",
    "    print ('Recall = {0}'.format(recall))\n",
    "    return(analysis.get_best_config(metric='keras_info/acc', mode='max'))\n",
    "\n",
    "def ZOOptSearch(task_data, task_id=0, cpu_resouce_fed=4):\n",
    "    from ray.tune.suggest.zoopt import ZOOptSearch\n",
    "    from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "    from zoopt import ValueType  # noqa: F401\n",
    "    \n",
    "    search_space={\n",
    "        \"lr\": tune.loguniform(0.001, 0.1),  \n",
    "        \"unit\": tune.uniform(20, 50),\n",
    "        \"dropout\": tune.loguniform(0.01, 0.3),\n",
    "    }\n",
    "    scheduler = AsyncHyperBandScheduler()\n",
    "    num_samples = 10\n",
    "    zoopt_search_config = {\n",
    "        \"parallel_num\": cpu_resouce_fed,\n",
    "    }\n",
    "\n",
    "    algo = ZOOptSearch(\n",
    "        algo=\"Asracos\",  # only support ASRacos currently\n",
    "        budget=num_samples,\n",
    "        # dim_dict=space,  # If you want to set the space yourself\n",
    "        **zoopt_search_config)\n",
    "    ray.shutdown()  # Restart Ray defensively in case the ray connection is lost. \n",
    "    ray.init(log_to_driver=False, num_cpus=cpu_resouce_fed)\n",
    "    ! rm -rf ~/ray_results/BayesOptSearch_mnist_task$task_id\n",
    "    analysis =tune.run(tune_mnist,\n",
    "        name=\"ZOOptSearch_mnist_task\"+str(task_id), verbose = 1,\n",
    "        scheduler=scheduler,\n",
    "        search_alg=algo,\n",
    "        num_samples=num_samples, \n",
    "        metric=\"mean_accuracy\",\n",
    "        mode=\"max\",\n",
    "        config=search_space,\n",
    "        stop={\"training_iteration\": 150})\n",
    "    time.sleep(1)\n",
    "    #from ray.tune import Analysis as analysis\n",
    "    #analysis = ray.tune.Analysis('/root/ray_results/BayesOptSearch_ASNM') \n",
    "    print(\"You can use any of the following columns to get the best model: \\n{}.\".format(\n",
    "        [k for k in analysis.dataframe() if k.startswith(\"keras_info\")]))\n",
    "    print(\"=\" * 10)\n",
    "    logdir = analysis.get_best_logdir(\"keras_info/acc\", mode=\"max\")\n",
    "    print('Best model:', analysis.get_best_config(metric='keras_info/acc', mode='max'))\n",
    "    # We saved the model as `model.h5` in the logdir of the trial.\n",
    "    from tensorflow.keras.models import load_model\n",
    "    tuned_model = load_model(logdir + \"/model.h5\", custom_objects =  {'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m})\n",
    "    tuned_model.summary()\n",
    "    image_size = 28\n",
    "    X_test = np.reshape(task_data[2],[-1, image_size, image_size])\n",
    "    Y_test = task_data[3]\n",
    "    tuned_loss, tuned_accuracy, f1_score, precision, recall = tuned_model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print(\"Loss is {:0.4f}\".format(tuned_loss))\n",
    "    print(\"Tuned accuracy is {:0.4f}\".format(tuned_accuracy))\n",
    "    print ('F1-score = {0}'.format(f1_score))\n",
    "    print ('Precision = {0}'.format(precision))\n",
    "    print ('Recall = {0}'.format(recall))\n",
    "    return(analysis.get_best_config(metric='keras_info/acc', mode='max'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/3 CPUs, 0/0 GPUs, 0.0/6.74 GiB heap, 0.0/2.29 GiB objects<br>Result logdir: /root/ray_results/Random_mnist_task4<br>Number of trials: 10/10 (10 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">        lr</th><th style=\"text-align: right;\">   unit</th><th style=\"text-align: right;\">     acc</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">    f1_m</th><th style=\"text-align: right;\">  precision_m</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>tune_mnist_7abd6_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.0201999</td><td style=\"text-align: right;\">0.00277963</td><td style=\"text-align: right;\">46.122 </td><td style=\"text-align: right;\">0.992142</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         13.3181</td><td style=\"text-align: right;\"> 0.0244629</td><td style=\"text-align: right;\">0.99218 </td><td style=\"text-align: right;\">     0.992221</td></tr>\n",
       "<tr><td>tune_mnist_7abd6_00001</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.0800977</td><td style=\"text-align: right;\">0.0687419 </td><td style=\"text-align: right;\">34.6523</td><td style=\"text-align: right;\">0.850773</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         12.1931</td><td style=\"text-align: right;\"> 0.388466 </td><td style=\"text-align: right;\">0.850766</td><td style=\"text-align: right;\">     0.850766</td></tr>\n",
       "<tr><td>tune_mnist_7abd6_00002</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.0274417</td><td style=\"text-align: right;\">0.0340264 </td><td style=\"text-align: right;\">35.5525</td><td style=\"text-align: right;\">0.693523</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         12.4236</td><td style=\"text-align: right;\">16.7834   </td><td style=\"text-align: right;\">0.689482</td><td style=\"text-align: right;\">     0.694075</td></tr>\n",
       "<tr><td>tune_mnist_7abd6_00003</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.123244 </td><td style=\"text-align: right;\">0.00237379</td><td style=\"text-align: right;\">22.4222</td><td style=\"text-align: right;\">0.979237</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         11.2315</td><td style=\"text-align: right;\"> 0.0384946</td><td style=\"text-align: right;\">0.979246</td><td style=\"text-align: right;\">     0.979246</td></tr>\n",
       "<tr><td>tune_mnist_7abd6_00004</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.199422 </td><td style=\"text-align: right;\">0.00763165</td><td style=\"text-align: right;\">24.7493</td><td style=\"text-align: right;\">0.982298</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         11.3235</td><td style=\"text-align: right;\"> 0.0312803</td><td style=\"text-align: right;\">0.982393</td><td style=\"text-align: right;\">     0.982556</td></tr>\n",
       "<tr><td>tune_mnist_7abd6_00005</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.0273745</td><td style=\"text-align: right;\">0.00353324</td><td style=\"text-align: right;\">32.4271</td><td style=\"text-align: right;\">0.989991</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         12.402 </td><td style=\"text-align: right;\"> 0.0226044</td><td style=\"text-align: right;\">0.989999</td><td style=\"text-align: right;\">     0.990081</td></tr>\n",
       "<tr><td>tune_mnist_7abd6_00006</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.0769428</td><td style=\"text-align: right;\">0.0180957 </td><td style=\"text-align: right;\">37.3951</td><td style=\"text-align: right;\">0.97444 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         13.2384</td><td style=\"text-align: right;\"> 0.0352407</td><td style=\"text-align: right;\">0.974393</td><td style=\"text-align: right;\">     0.974594</td></tr>\n",
       "<tr><td>tune_mnist_7abd6_00007</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.0236908</td><td style=\"text-align: right;\">0.00340125</td><td style=\"text-align: right;\">28.5406</td><td style=\"text-align: right;\">0.989164</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         11.8775</td><td style=\"text-align: right;\"> 0.0304775</td><td style=\"text-align: right;\">0.989173</td><td style=\"text-align: right;\">     0.989174</td></tr>\n",
       "<tr><td>tune_mnist_7abd6_00008</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.0175643</td><td style=\"text-align: right;\">0.00451989</td><td style=\"text-align: right;\">24.3249</td><td style=\"text-align: right;\">0.987178</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         11.4118</td><td style=\"text-align: right;\"> 0.0320995</td><td style=\"text-align: right;\">0.987255</td><td style=\"text-align: right;\">     0.987424</td></tr>\n",
       "<tr><td>tune_mnist_7abd6_00009</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.0189807</td><td style=\"text-align: right;\">0.0846956 </td><td style=\"text-align: right;\">48.8068</td><td style=\"text-align: right;\">0.492679</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         11.7387</td><td style=\"text-align: right;\"> 0.693259 </td><td style=\"text-align: right;\">0.492579</td><td style=\"text-align: right;\">     0.492579</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-22 09:46:13,631\tINFO tune.py:439 -- Total run time: 62.85 seconds (62.67 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can use any of the following columns to get the best model: \n",
      "['keras_info/loss', 'keras_info/acc', 'keras_info/f1_m', 'keras_info/precision_m', 'keras_info/recall_m', 'keras_info/val_loss', 'keras_info/val_acc', 'keras_info/val_f1_m', 'keras_info/val_precision_m', 'keras_info/val_recall_m'].\n",
      "==========\n",
      "Best model: tune_mnist_7abd6_00005 lr: 0.0035332382550846446 unit: 32.42705057243154 dropout: 0.027374485268163815\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "RNN (SimpleRNN)              (None, 32)                1952      \n",
      "_________________________________________________________________\n",
      "dense_output (Dense)         (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 2,282\n",
      "Trainable params: 2,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Loss is 0.0225\n",
      "Tuned accuracy is 0.9922\n",
      "F1-score = 0.9919621348381042\n",
      "Precision = 0.9919621348381042\n",
      "Recall = 0.9919621348381042\n",
      "Train on 12089 samples, validate on 2042 samples\n",
      "Epoch 1/10\n",
      "12089/12089 [==============================] - 6s 530us/sample - loss: 0.6413 - acc: 0.8166 - f1_m: 0.8011 - precision_m: 0.8093 - recall_m: 0.7963 - val_loss: 0.1019 - val_acc: 0.9706 - val_f1_m: 0.9707 - val_precision_m: 0.9707 - val_recall_m: 0.9707\n",
      "Epoch 2/10\n",
      "12089/12089 [==============================] - 5s 378us/sample - loss: 0.1030 - acc: 0.9645 - f1_m: 0.9648 - precision_m: 0.9648 - recall_m: 0.9647 - val_loss: 0.0523 - val_acc: 0.9819 - val_f1_m: 0.9819 - val_precision_m: 0.9819 - val_recall_m: 0.9819\n",
      "Epoch 3/10\n",
      "12089/12089 [==============================] - 5s 380us/sample - loss: 0.0716 - acc: 0.9758 - f1_m: 0.9758 - precision_m: 0.9760 - recall_m: 0.9756 - val_loss: 0.0440 - val_acc: 0.9814 - val_f1_m: 0.9814 - val_precision_m: 0.9814 - val_recall_m: 0.9814\n",
      "Epoch 4/10\n",
      "12089/12089 [==============================] - 4s 323us/sample - loss: 0.0604 - acc: 0.9802 - f1_m: 0.9801 - precision_m: 0.9803 - recall_m: 0.9798 - val_loss: 0.0276 - val_acc: 0.9922 - val_f1_m: 0.9921 - val_precision_m: 0.9921 - val_recall_m: 0.9921\n",
      "Epoch 5/10\n",
      "12089/12089 [==============================] - 4s 320us/sample - loss: 0.0459 - acc: 0.9849 - f1_m: 0.9848 - precision_m: 0.9848 - recall_m: 0.9848 - val_loss: 0.0223 - val_acc: 0.9941 - val_f1_m: 0.9941 - val_precision_m: 0.9941 - val_recall_m: 0.9941\n",
      "Epoch 6/10\n",
      "12089/12089 [==============================] - 4s 325us/sample - loss: 0.0441 - acc: 0.9862 - f1_m: 0.9861 - precision_m: 0.9862 - recall_m: 0.9861 - val_loss: 0.0238 - val_acc: 0.9907 - val_f1_m: 0.9907 - val_precision_m: 0.9907 - val_recall_m: 0.9907\n",
      "Epoch 7/10\n",
      "12089/12089 [==============================] - 4s 331us/sample - loss: 0.0436 - acc: 0.9861 - f1_m: 0.9864 - precision_m: 0.9866 - recall_m: 0.9862 - val_loss: 0.0508 - val_acc: 0.9853 - val_f1_m: 0.9853 - val_precision_m: 0.9853 - val_recall_m: 0.9853\n",
      "Epoch 8/10\n",
      "12089/12089 [==============================] - 4s 332us/sample - loss: 0.0349 - acc: 0.9874 - f1_m: 0.9874 - precision_m: 0.9877 - recall_m: 0.9871 - val_loss: 0.0122 - val_acc: 0.9971 - val_f1_m: 0.9971 - val_precision_m: 0.9971 - val_recall_m: 0.9971\n",
      "Epoch 9/10\n",
      "12089/12089 [==============================] - 4s 326us/sample - loss: 0.0307 - acc: 0.9908 - f1_m: 0.9908 - precision_m: 0.9909 - recall_m: 0.9908 - val_loss: 0.0106 - val_acc: 0.9966 - val_f1_m: 0.9966 - val_precision_m: 0.9966 - val_recall_m: 0.9966\n",
      "Epoch 10/10\n",
      "12089/12089 [==============================] - 4s 332us/sample - loss: 0.0285 - acc: 0.9910 - f1_m: 0.9910 - precision_m: 0.9910 - recall_m: 0.9910 - val_loss: 0.0111 - val_acc: 0.9966 - val_f1_m: 0.9966 - val_precision_m: 0.9966 - val_recall_m: 0.9966\n",
      "Search algorithm random_search took 574.3160405158997.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pdb\n",
    "import time\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        last_model_stats = Model_Perf_save\n",
    "        for i,lay in enumerate(model.layers):\n",
    "            last_model_size = last_model_stats['shape'][-1][2*i+1][0]\n",
    "            layer_weights = lay.get_weights()\n",
    "            layer_weights[0][:last_model_stats['weights'][-1][3*i].shape[0],:last_model_size] = last_model_stats['weights'][-1][3*i]\n",
    "            if i != len(model.layers)-1: #for last (dense) layer\n",
    "                layer_weights[1][:last_model_stats['weights'][-1][3*i+1].shape[0],:last_model_size] = last_model_stats['weights'][-1][3*i+1]\n",
    "                layer_weights[2][:last_model_size] = last_model_stats['weights'][-1][3*i+2]\n",
    "            else:\n",
    "                layer_weights[1][:last_model_size] = last_model_stats['weights'][-1][3*i+1]\n",
    "            model.layers[i].set_weights(layer_weights)      \n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        last_model_stats = Model_Perf_save\n",
    "        for i,lay in enumerate(model.layers):\n",
    "            last_model_size = last_model_stats['shape'][-1][2*i+1][0]\n",
    "            layer_weights = lay.get_weights()\n",
    "            layer_weights[0][:last_model_stats['weights'][-1][3*i].shape[0],:last_model_size] = last_model_stats['weights'][-1][3*i]\n",
    "            if i != len(model.layers)-1: #for last (dense) layer\n",
    "                layer_weights[1][:last_model_stats['weights'][-1][3*i+1].shape[0],:last_model_size] = last_model_stats['weights'][-1][3*i+1]\n",
    "                layer_weights[2][:last_model_size] = last_model_stats['weights'][-1][3*i+2]\n",
    "            else:\n",
    "                layer_weights[1][:last_model_size] = last_model_stats['weights'][-1][3*i+1]\n",
    "            model.layers[i].set_weights(layer_weights)  \n",
    "        \n",
    "def create_task(data_path):\n",
    "    data = pickle.load(open(data_path, \"rb\"))\n",
    "    return data\n",
    "\n",
    "def measure_CPU_Mem():\n",
    "    import psutil\n",
    "    CPU_usage_dump = []\n",
    "    Mem_usage_dump = []  \n",
    "    while True:\n",
    "        CPU_usage_dump.append(psutil.cpu_percent())\n",
    "        Mem_usage_dump.append(psutil.virtual_memory().percent)\n",
    "        f_cpu=open(\"CPU_used.txt\", \"wb\")\n",
    "        f_mem=open(\"Mem_used.txt\", \"wb\")\n",
    "        pickle.dump(CPU_usage_dump, f_cpu) \n",
    "        pickle.dump(Mem_usage_dump, f_mem)     \n",
    "        f_cpu.close()\n",
    "        f_mem.close()\n",
    "        time.sleep(1)\n",
    "\n",
    "import multiprocessing\n",
    "task_list = create_task('mnist_tasks.pkl')\n",
    "num_tasks=5\n",
    "num_labels=10\n",
    "Model_Perf_save = {}\n",
    "Model_Perf_save['tr_acc'] = []\n",
    "Model_Perf_save['val_acc'] = []\n",
    "Model_Perf_save['precision'] = []\n",
    "Model_Perf_save['recall'] = []\n",
    "Model_Perf_save['f1_score'] = []\n",
    "Model_Perf_save['shape'] = []\n",
    "Model_Perf_save['weights'] = []\n",
    "Model_Perf_save['learn_rate'] = []\n",
    "Model_Perf_save['dropout'] = []\n",
    "cpu_resouce_fed = 3\n",
    "for search_algo in [ \n",
    "                    random_search,\n",
    "                    #ASHA_search,\n",
    "                    #mutation_pbtsearch,\n",
    "                    #BayesOptSearch,\n",
    "                    #NeverGradSearch,\n",
    "                    #OptunaSearch,\n",
    "                    #ZOOptSearch,\n",
    "                    #hyperopt_search\n",
    "                    ]:\n",
    "    cpu_mem_collection = multiprocessing.Process(target=measure_CPU_Mem)\n",
    "    cpu_mem_collection.start()\n",
    "    start_time = time.time()\n",
    "    for task_id in range(0,num_tasks):\n",
    "        !rm -rf task_dataset.pkl\n",
    "        f = open('task_dataset.pkl', 'wb')\n",
    "        pickle.dump(task_list[task_id], f)\n",
    "        f.close()\n",
    "        hyper_param = search_algo(task_list[task_id], task_id, cpu_resouce_fed)\n",
    "        image_size = 28\n",
    "        if task_id == 0:\n",
    "            model = create_model(learning_rate=hyper_param['lr'], RNN_units=int(hyper_param['unit']), dropout=hyper_param['dropout'])\n",
    "            #call one of the search algorithm\n",
    "            history = model.fit(np.reshape(task_list[task_id][0],[-1, image_size, image_size]), \n",
    "                  task_list[task_id][1], batch_size=128, epochs=10, verbose=1,\n",
    "                  validation_data=(np.reshape(task_list[task_id][2],[-1, image_size, image_size]), task_list[task_id][3]))\n",
    "        else:\n",
    "            rnn_units = hyper_param[\"unit\"] + Model_Perf_save['shape'][-1][1][0]\n",
    "            model = create_model(learning_rate=hyper_param['lr'], RNN_units=int(rnn_units), dropout=hyper_param['dropout'])\n",
    "            history = model.fit(np.reshape(task_list[task_id][0],[-1, image_size, image_size]),\n",
    "                  task_list[task_id][1], batch_size=128, epochs=10, verbose=1,\n",
    "                  validation_data=(np.reshape(task_list[task_id][2],[-1, image_size, image_size]), task_list[task_id][3]), callbacks  = [LossHistory()])\n",
    "        loss_and_metrics = model.evaluate(np.reshape(task_list[task_id][0],[-1, image_size, image_size]), task_list[task_id][1], verbose=0)\n",
    "        Model_Perf_save['tr_acc'].append(loss_and_metrics[1])\n",
    "        loss_and_metrics = model.evaluate(np.reshape(task_list[task_id][4],[-1, image_size, image_size]), task_list[task_id][5], verbose=0)\n",
    "        Model_Perf_save['val_acc'].append(loss_and_metrics[1])\n",
    "        Model_Perf_save['f1_score'].append(loss_and_metrics[2])\n",
    "        Model_Perf_save['precision'].append(loss_and_metrics[3])\n",
    "        Model_Perf_save['recall'].append(loss_and_metrics[4])\n",
    "        Model_Perf_save['shape'].append([i.shape for i in model.get_weights()])\n",
    "        Model_Perf_save['learn_rate'].append(hyper_param[\"lr\"])\n",
    "        Model_Perf_save['dropout'].append(hyper_param[\"dropout\"])\n",
    "        Model_Perf_save['weights'].append(model.get_weights()) \n",
    "    end_time = time.time()\n",
    "    print('Search algorithm {} took {}.'.format(search_algo.__name__, end_time - start_time))\n",
    "    \n",
    "    f=open(\"time_taken.txt\", \"a+\")\n",
    "    f.write('Time taken for algo {} is {}. \\n'.format(search_algo.__name__, end_time-start_time))\n",
    "\n",
    "    try:\n",
    "        f_cpu=open(\"CPU_used.txt\", \"rb\")\n",
    "        f_mem=open(\"Mem_used.txt\", \"rb\")\n",
    "        cpu_usage = pickle.load(f_cpu)\n",
    "        mem_usage = pickle.load(f_mem)\n",
    "        f_cpu.close()\n",
    "        f_mem.close()\n",
    "        cpu_mem_collection.terminate()\n",
    "        cpu_mem_collection.join()\n",
    "        f.write('CPU used is {}. \\n'.format(np.mean(cpu_usage)))\n",
    "        f.write('Memory used is {}. \\n \\n'.format(np.mean(mem_usage)))\n",
    "        f.close()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Algorithm: random_search\n",
      "Training accuracy for tasks: [0.9979471, 0.9967149, 0.9997538, 0.99211866, 0.9947059]\n",
      "Validation accuracy for tasks: [0.99763596, 0.99839914, 0.99647534, 0.9878971, 0.996572]\n",
      "Precision: [0.9976679, 0.998411, 0.9965278, 0.98790324, 0.99658203]\n",
      "Recall: [0.9976679, 0.998411, 0.9965278, 0.98790324, 0.99658203]\n",
      "F1 score: [0.9976679, 0.998411, 0.9965278, 0.98790324, 0.99658203]\n",
      "Nodes in hidden layer:  [(28, 46), (28, 78), (28, 124), (28, 148), (28, 194)]\n",
      "Learning rates:  [0.002779625851893939, 0.0035332382550846446, 0.002779625851893939, 0.0045198903102267275, 0.002779625851893939]\n",
      "Dropout probability:  [0.020199901797267196, 0.027374485268163815, 0.020199901797267196, 0.017564276989659063, 0.020199901797267196]\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for j,search_algo in enumerate([\n",
    "                    #ASHA_search, \n",
    "                    random_search,\n",
    "                    #mutation_pbtsearch,\n",
    "                    #BayesOptSearch,\n",
    "                    #NeverGradSearch,\n",
    "                    #OptunaSearch,\n",
    "                    #ZOOptSearch,\n",
    "                    #hyperopt_search\n",
    "                    ]):\n",
    "    print('Search Algorithm: {0}'.format(search_algo.__name__))\n",
    "    print('Training accuracy for tasks:',Model_Perf_save['tr_acc'][j*num_tasks:j*num_tasks+num_tasks])\n",
    "    print('Validation accuracy for tasks:',Model_Perf_save['val_acc'][j*num_tasks:j*num_tasks+num_tasks])\n",
    "    print('Precision:',Model_Perf_save['precision'][j*num_tasks:j*num_tasks+num_tasks])\n",
    "    print('Recall:',Model_Perf_save['recall'][j*num_tasks:j*num_tasks+num_tasks])\n",
    "    print('F1 score:',Model_Perf_save['f1_score'][j*num_tasks:j*num_tasks+num_tasks])\n",
    "    print('Nodes in hidden layer: ',[(i[0])for i in Model_Perf_save['shape']][j*num_tasks:j*num_tasks+num_tasks])\n",
    "    print('Learning rates: ', Model_Perf_save['learn_rate'][j*num_tasks:j*num_tasks+num_tasks])\n",
    "    print('Dropout probability: ', Model_Perf_save['dropout'][j*num_tasks:j*num_tasks+num_tasks])\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting the weights/bias matrix size after learning each task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For task 1.------ [(28, 46), (46, 46), (46,), (46, 10), (10,)]\n",
      "For task 2.------ [(28, 78), (78, 78), (78,), (78, 10), (10,)]\n",
      "For task 3.------ [(28, 124), (124, 124), (124,), (124, 10), (10,)]\n",
      "For task 4.------ [(28, 148), (148, 148), (148,), (148, 10), (10,)]\n",
      "For task 5.------ [(28, 194), (194, 194), (194,), (194, 10), (10,)]\n"
     ]
    }
   ],
   "source": [
    "for i,task in enumerate(Model_Perf_save['weights']):\n",
    "    print(f'For task {i+1}.------ {[layer.shape for layer in task]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing the weights/bias to verify that current weights are frozen while learning future tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------Comparing with 1th task.----------------\n",
      "For 1th weight array.\n",
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True]\n",
      "[[ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]]\n",
      "For 2th weight array.\n",
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True]\n",
      "[[ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]]\n",
      "For 3th weight array.\n",
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True]\n",
      "[[ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]]\n",
      "For 4th weight array.\n",
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True]\n",
      "[[ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]]\n",
      "--------------Comparing with 2th task.----------------\n",
      "For 2th weight array.\n",
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True]\n",
      "[[ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]]\n",
      "For 3th weight array.\n",
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True]\n",
      "[[ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]]\n",
      "For 4th weight array.\n",
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True]\n",
      "[[ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True  True  True]]\n",
      "--------------Comparing with 3th task.----------------\n",
      "For 3th weight array.\n",
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n",
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "For 4th weight array.\n",
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n",
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "--------------Comparing with 4th task.----------------\n",
      "For 4th weight array.\n",
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n",
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "--------------Comparing with 5th task.----------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(Model_Perf_save['weights'])):\n",
    "    print(f'--------------Comparing with {i+1}th task.----------------')\n",
    "    for j in range((i+1), len(Model_Perf_save['weights'])):\n",
    "        print(f'For {j}th weight array.')\n",
    "        for weightarray_num in range(4):   #Looping over all the weight arry except last \n",
    "            try:\n",
    "                print(Model_Perf_save['weights'][i][weightarray_num] == Model_Perf_save['weights'][i][weightarray_num][:Model_Perf_save['weights'][i][:weightarray_num].shape[0],:Model_Perf_save['weights'][i][weightarray_num].shape[1]])\n",
    "            except:\n",
    "                print(Model_Perf_save['weights'][i][weightarray_num] == Model_Perf_save['weights'][i][weightarray_num][:len(Model_Perf_save['weights'][i][weightarray_num])])\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting weights centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters for task 1 is 3920.\n",
      "Total number of parameters for task 2 is 9136.\n",
      "Total number of parameters for task 3 is 20222.\n",
      "Total number of parameters for task 4 is 27686.\n",
      "Total number of parameters for task 5 is 45212.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['normal'] not found. Falling back to DejaVu Sans.\n",
      "findfont: Font family ['normal'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "import pdb\n",
    "import collections\n",
    "\n",
    "def flatten(weights):\n",
    "    w = []\n",
    "    for l in weights:\n",
    "        if isinstance(l, collections.Iterable):\n",
    "            w = w + flatten(l)\n",
    "        else:\n",
    "            w = w + [l]\n",
    "    return w\n",
    "\n",
    "\n",
    "all_weights = {}\n",
    "boxplot_data = []\n",
    "for i,task in enumerate(Model_Perf_save['weights']):\n",
    "    all_weights[i+1] = flatten(task)\n",
    "    boxplot_data.append(all_weights[i+1])\n",
    "    print(f'Total number of parameters for task {i+1} is {len(all_weights[i+1])}.')\n",
    "import matplotlib\n",
    "font = {'family' : 'normal',\n",
    "        'weight'  : 'normal',\n",
    "        'size'   : 12}\n",
    "matplotlib.rc('font', **font)\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize =(5, 3))\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "bp = ax.boxplot(boxplot_data) \n",
    "ax.set_xlabel(r'Task ($\\tau$), Size of $\\mathbf{\\theta}$.')\n",
    "plt.title('MNIST: Parameters box plot.')\n",
    "ax.set_ylabel(r\"Value of $\\mathbf{\\theta}$'s .\")\n",
    "ax.set_xticklabels([(i+1,len(all_weights[i+1])) for i in range(len(all_weights.keys()))], rotation = 45)\n",
    "plt.savefig('MNIST_params_boxplot.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10324311648275664, 0.9632713, 0.9631486, 0.9638823, 0.9624399]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# later...\n",
    " \n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "optimizer = Adam(clipvalue=0.5)\n",
    "loaded_model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy',f1_m,precision_m, recall_m])\n",
    "loaded_model.evaluate(np.reshape(task_list[task_id][4],[-1, image_size, image_size]), task_list[task_id][5], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.10324311648275664, 0.9632713, 0.9631486, 0.9638823, 0.9624399]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_id=4\n",
    "current_stage_weights = Model_Perf_save['weights'][-1].copy()\n",
    "select_task_shape = Model_Perf_save['shape'][task_id]\n",
    "for j,weight_size in enumerate(select_task_shape):\n",
    "    if len(weight_size) == 2:\n",
    "        current_stage_weights[j][weight_size[0]:,weight_size[1]:]=0\n",
    "    else:\n",
    "        current_stage_weights[j][weight_size[0]:]=0\n",
    "loaded_model.set_weights(current_stage_weights)\n",
    "loaded_model.evaluate(np.reshape(task_list[task_id][4],[-1, image_size, image_size]), task_list[task_id][5], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.10324311648275664, 0.9632713, 0.9631486, 0.9638823, 0.9624399]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.set_weights(Model_Perf_save['weights'][-1])\n",
    "loaded_model.evaluate(np.reshape(task_list[task_id][4],[-1, image_size, image_size]), task_list[task_id][5], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (array([], dtype=int64), array([], dtype=int64))\n",
      "1 (array([], dtype=int64), array([], dtype=int64))\n",
      "2 (array([], dtype=int64),)\n",
      "3 (array([], dtype=int64), array([], dtype=int64))\n",
      "4 (array([], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(loaded_model.get_weights()):\n",
    "    comparision_result = j == Model_Perf_save['weights'][-1][i]\n",
    "    print(i, np.where(comparision_result == False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
